{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItQZdSUefSm_"
   },
   "source": [
    "# **Mount Google Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20246,
     "status": "ok",
     "timestamp": 1749878550747,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "haAG2nYDxGP-",
    "outputId": "39c89906-8be5-4740-b493-5bbcda43831d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBlbCpEofOsp"
   },
   "source": [
    "# **Instalasi Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 251916,
     "status": "ok",
     "timestamp": 1749972286862,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "wZtvrKSyfEEu",
    "outputId": "a99b0e5b-281c-44fc-ba99-b67e91e65c86"
   },
   "outputs": [],
   "source": [
    "# üì¶ Install dependencies\n",
    "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
    "!pip install -q pycocotools\n",
    "\n",
    "# üîß Setup: Import\n",
    "import os\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "import random\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyGbgVbS1ImQ"
   },
   "source": [
    "# **Register Dataset COCO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5734,
     "status": "ok",
     "timestamp": 1749972300129,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "bbzkh1YegWxW",
    "outputId": "0c7b1c65-d373-4b6a-ada2-c11e8ed7498a"
   },
   "outputs": [],
   "source": [
    "# Set root folder di Google Drive\n",
    "dataset_root = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Dataset/dataset_new\"\n",
    "\n",
    "# Buat path lengkap ke JSON dan folder gambar\n",
    "train_json = os.path.join(dataset_root, \"train/_annotations.coco.json\")\n",
    "val_json = os.path.join(dataset_root, \"valid/_annotations.coco.json\")\n",
    "test_json = os.path.join(dataset_root, \"test/_annotations.coco.json\")\n",
    "train_img_dir = os.path.join(dataset_root, \"train\")\n",
    "val_img_dir = os.path.join(dataset_root, \"valid\")\n",
    "test_img_dir = os.path.join(dataset_root, \"test\")\n",
    "\n",
    "# ‚úÖ Cek apakah file dan folder ada\n",
    "print(\"Train JSON exists:\", os.path.exists(train_json))\n",
    "print(\"Train Image Dir exists:\", os.path.exists(train_img_dir))\n",
    "\n",
    "# üóÇ Daftarkan dataset ke Detectron2\n",
    "register_coco_instances(\"roboflow_train\", {}, train_json, train_img_dir)\n",
    "register_coco_instances(\"roboflow_val\", {}, val_json, val_img_dir)\n",
    "register_coco_instances(\"roboflow_test\", {}, test_json, test_img_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ah8bfd6J1Nl4"
   },
   "source": [
    "# **Konfigurasi Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 370,
     "status": "ok",
     "timestamp": 1749972304433,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "tc-CAJlQgbvv",
    "outputId": "e5c46649-74a2-4593-ae57-5c0f99d76638"
   },
   "outputs": [],
   "source": [
    "from detectron2 import model_zoo\n",
    "\n",
    "# üß† Configure RetinaNet\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"roboflow_train\",)\n",
    "cfg.DATASETS.TEST = (\"roboflow_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.MODEL.WEIGHTS = \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
    "cfg.SOLVER.IMS_PER_BATCH = 16\n",
    "cfg.SOLVER.BASE_LR = 0.0001\n",
    "cfg.SOLVER.MAX_ITER = 2800\n",
    "cfg.TEST.EVAL_PERIOD = 500  # Evaluate every 500 iterations\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.MODEL.RETINANET.NUM_CLASSES = 4  # ‚ö†Ô∏è Update this if more than 1 class\n",
    "cfg.OUTPUT_DIR = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_SGD\"\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yvrKae-1RSi"
   },
   "source": [
    "# **Training Skenario 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6183876,
     "status": "ok",
     "timestamp": 1749885055398,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "QrpA7raHgn2R",
    "outputId": "52dc0c46-db04-4605-bf82-46a13d1a6a7f"
   },
   "outputs": [],
   "source": [
    "#trainer = DefaultTrainer(cfg)\n",
    "#trainer.resume_or_load(resume=False)\n",
    "#trainer.train()\n",
    "\n",
    "# üöÄ Train with saving best model\n",
    "from detectron2.engine.hooks import BestCheckpointer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.utils.events import EventStorage\n",
    "\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "\n",
    "    def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        # Save the best checkpoint (based on bbox/AP)\n",
    "        hooks.insert(\n",
    "            -1,\n",
    "            BestCheckpointer(\n",
    "                cfg.TEST.EVAL_PERIOD,\n",
    "                checkpointer=DetectionCheckpointer(self.model, cfg.OUTPUT_DIR),\n",
    "                val_metric=\"bbox/AP\",\n",
    "                mode=\"max\",\n",
    "                file_prefix=\"best_model\"\n",
    "            )\n",
    "        )\n",
    "        return hooks\n",
    "\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70DUe2cg2LKn"
   },
   "source": [
    "# **Simpan Konfigurasi Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RhGW1Q85-B_c"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(cfg.OUTPUT_DIR, \"config.yaml\"), \"w\") as f:\n",
    "    f.write(cfg.dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3GJqXRQ-VM6"
   },
   "source": [
    "# **Prediksi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 890
    },
    "executionInfo": {
     "elapsed": 1944,
     "status": "ok",
     "timestamp": 1749885232155,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "omR1knib-XDd",
    "outputId": "ece87fdb-33b1-4762-da74-bf909fa4cb07"
   },
   "outputs": [],
   "source": [
    "# üß† Load the trained model\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"best_model.pth\")  # Load the weights from your training\n",
    "#cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Set threshold to 50% for detection\n",
    "\n",
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# üì∏ Read the image\n",
    "#image_path = '/content/valid/00000732_005_jpg.rf.3541c4c659fec2d5d003b4fb7a380dea.jpg'\n",
    "image_path = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Dataset/test/9e90a23fb8d5ce13eb766d538afcafea_jpg.rf.0781f1855ffb9a79518d927eefc0a0cd.jpg\"\n",
    "im = cv2.imread(image_path)\n",
    "\n",
    "# üß† Run inference\n",
    "outputs = predictor(im)\n",
    "\n",
    "# Filter instances with confidence\n",
    "confidence = 0.2\n",
    "instances = outputs[\"instances\"]\n",
    "scores = instances.scores\n",
    "filtered_instances = instances[scores > confidence]\n",
    "\n",
    "# üñºÔ∏è Visualize the results\n",
    "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(\"roboflow_train\"), scale=1)\n",
    "v = v.draw_instance_predictions(filtered_instances.to(\"cpu\"))\n",
    "\n",
    "# Show the image with filtered instances\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(v.get_image())\n",
    "plt.show()\n",
    "\n",
    "# Optionally, print out the number of detections\n",
    "print(f\"Detected {len(filtered_instances)} objects with confidence > {confidence*100}%.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdxeB_1t2ZtC"
   },
   "source": [
    "# **Grafik Record Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1749885240669,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "vVYGs3Ff-hVL",
    "outputId": "48118d6e-89a4-49da-ec4a-83e0143fdc87"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tentukan path ke file metrics.json\n",
    "metrics_file = '/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_SGD/metrics.json'  # Ganti dengan path file Anda\n",
    "\n",
    "# Menyaring data untuk total_loss\n",
    "iterations = []\n",
    "total_loss = []\n",
    "\n",
    "# Membaca file JSON baris per baris\n",
    "with open(metrics_file, 'r') as f:\n",
    "    for line in f:\n",
    "        # Memuat setiap baris JSON\n",
    "        entry = json.loads(line)\n",
    "\n",
    "        # Menyaring data untuk iteration dan total_loss\n",
    "        if 'iteration' in entry and 'total_loss' in entry:\n",
    "            iterations.append(entry['iteration'])\n",
    "            total_loss.append(entry['total_loss'])\n",
    "\n",
    "# Membuat grafik untuk total loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(iterations, total_loss, label=\"Total Loss\", color='tab:blue')\n",
    "\n",
    "# Menambahkan judul dan label sumbu\n",
    "plt.title('Total Loss over Iterations')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Total Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "# Menampilkan grafik\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1749885254609,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "ZwlD7oYY-oPY",
    "outputId": "af8a3dfe-ec6e-480a-e0ea-60ef90cc808e"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tentukan path ke file metrics.json\n",
    "metrics_file = '/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_SGD/metrics.json'  # Ganti dengan path file Anda\n",
    "\n",
    "# Menyaring data untuk AP\n",
    "iterations = []\n",
    "bbox_ap = []\n",
    "bbox_ap50 = []\n",
    "bbox_ap75 = []\n",
    "bbox_ap_cardio = []\n",
    "bbox_ap_nodule = []\n",
    "bbox_ap_pneumo = []\n",
    "\n",
    "# Membaca file JSON baris per baris\n",
    "with open(metrics_file, 'r') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            entry = json.loads(line)\n",
    "\n",
    "            # Pastikan hanya memasukkan data yang mengandung metrik 'bbox/AP'\n",
    "            if 'bbox/AP' in entry:\n",
    "                iterations.append(entry['iteration'])\n",
    "                bbox_ap.append(entry['bbox/AP'])\n",
    "                bbox_ap50.append(entry.get('bbox/AP50', None))\n",
    "                bbox_ap75.append(entry.get('bbox/AP75', None))\n",
    "                bbox_ap_cardio.append(entry.get('bbox/AP-Cardiomegaly', None))\n",
    "                bbox_ap_nodule.append(entry.get('bbox/AP-Nodule-Mass', None))\n",
    "                bbox_ap_pneumo.append(entry.get('bbox/AP-Pneumothorax', None))\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing line: {e}\")\n",
    "            continue\n",
    "\n",
    "# Memastikan ada data untuk plotting\n",
    "print(f\"Total data points: {len(iterations)}\")\n",
    "\n",
    "# Jika ada data untuk plotting, buat grafik\n",
    "if iterations:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plotting berbagai metrik AP\n",
    "    plt.plot(iterations, bbox_ap, label=\"bbox/AP\", color='tab:blue')\n",
    "    plt.plot(iterations, bbox_ap50, label=\"bbox/AP50\", color='tab:orange')\n",
    "    plt.plot(iterations, bbox_ap75, label=\"bbox/AP75\", color='tab:green')\n",
    "    plt.plot(iterations, bbox_ap_cardio, label=\"bbox/AP-Cardiomegaly\", color='tab:red')\n",
    "    plt.plot(iterations, bbox_ap_nodule, label=\"bbox/AP-Nodule-Mass\", color='tab:purple')\n",
    "    plt.plot(iterations, bbox_ap_pneumo, label=\"bbox/AP-Pneumothorax\", color='tab:brown')\n",
    "\n",
    "    # Menambahkan judul dan label sumbu\n",
    "    plt.title('Average Precision (AP) over Iterations')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Average Precision (AP)')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Menampilkan legenda\n",
    "    plt.legend()\n",
    "\n",
    "    # Menampilkan grafik\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Tidak ada data untuk plot.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1749885267860,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "smHSxi_u-w2_",
    "outputId": "6938207e-03fe-4294-a896-eec75d5851e1"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Menentukan path file metrics.json di Google Drive\n",
    "file_path = '/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_SGD/metrics.json'\n",
    "\n",
    "# Memuat file metrics.json\n",
    "with open(file_path, 'r') as file:\n",
    "    data = [json.loads(line) for line in file.readlines()]\n",
    "\n",
    "# Menyaring nilai AP per kelas dari data terakhir\n",
    "metrics = data[-1]  # Mengambil data terakhir yang berisi AP\n",
    "\n",
    "# Mengambil nilai AP per kelas\n",
    "ap_values = {\n",
    "    \"Cardiomegaly\": metrics.get('bbox/AP-Cardiomegaly', 0),\n",
    "    \"Nodule-Mass\": metrics.get('bbox/AP-Nodule-Mass', 0),\n",
    "    \"Pneumothorax\": metrics.get('bbox/AP-Pneumothorax', 0),\n",
    "}\n",
    "\n",
    "# Menghitung mAP (mean Average Precision)\n",
    "ap_values_list = list(ap_values.values())\n",
    "map_score = sum(ap_values_list) / len(ap_values_list)\n",
    "\n",
    "# Menampilkan hasil\n",
    "print(\"AP per kelas:\")\n",
    "for class_name, ap in ap_values.items():\n",
    "    print(f\"{class_name}: {ap:.4f}\")\n",
    "\n",
    "print(f\"\\nmAP: {map_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1749885275153,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "DdcfpUrF-7JX",
    "outputId": "2c439634-c4c6-4e27-aef5-c80ee599638d"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Menentukan path file metrics.json (update dengan path yang sesuai)\n",
    "file_path = '/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_SGD/metrics.json'\n",
    "\n",
    "# Memuat file metrics.json\n",
    "with open(file_path, 'r') as file:\n",
    "    data = [json.loads(line) for line in file.readlines()]\n",
    "\n",
    "# Menyaring nilai AP per kelas dari data terakhir\n",
    "ap_per_iteration = []\n",
    "map_per_iteration = []\n",
    "\n",
    "# Menyaring nilai AP per kelas dan mAP dari setiap iterasi\n",
    "for metrics in data:\n",
    "    # Mengecek apakah nilai AP ada dalam data\n",
    "    if 'bbox/AP-Cardiomegaly' in metrics and 'bbox/AP-Nodule-Mass' in metrics and 'bbox/AP-Pneumothorax' in metrics:\n",
    "        ap_values = {\n",
    "            \"Cardiomegaly\": metrics.get('bbox/AP-Cardiomegaly', 0),\n",
    "            \"Nodule-Mass\": metrics.get('bbox/AP-Nodule-Mass', 0),\n",
    "            \"Pneumothorax\": metrics.get('bbox/AP-Pneumothorax', 0),\n",
    "        }\n",
    "\n",
    "        # Menghitung mAP (mean Average Precision)\n",
    "        ap_values_list = list(ap_values.values())\n",
    "        map_score = sum(ap_values_list) / len(ap_values_list)\n",
    "\n",
    "        ap_per_iteration.append(ap_values)\n",
    "        map_per_iteration.append(map_score)\n",
    "\n",
    "# Menyiapkan data untuk grafik\n",
    "iterations = range(1, len(map_per_iteration) + 1)\n",
    "\n",
    "# Plotting mAP per iterasi\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(iterations, map_per_iteration, label='mAP (mean Average Precision)', color='blue', linewidth=2)\n",
    "\n",
    "# Menambahkan grafik untuk setiap kelas\n",
    "for class_name in ap_per_iteration[0].keys():\n",
    "    class_ap_values = [ap[class_name] for ap in ap_per_iteration]\n",
    "    plt.plot(iterations, class_ap_values, label=f'AP-{class_name}', linestyle='--')\n",
    "\n",
    "# Menambahkan label dan judul\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Average Precision')\n",
    "plt.title('mAP and AP per Class over Iterations')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Menampilkan grafik\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 568,
     "status": "ok",
     "timestamp": 1749885286421,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "6ZSwEPXH_DbG",
    "outputId": "f1c89bda-ef5f-4da8-d673-7b56c3dbbedd"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Path file di Google Drive (sesuaikan dengan path file Anda)\n",
    "file_path = '/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_SGD/metrics.json'\n",
    "\n",
    "# Memuat data dari file metrics.json\n",
    "with open(file_path, 'r') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# Menyiapkan data untuk plot\n",
    "iterations = []\n",
    "loss_cls_values = []\n",
    "loss_box_reg_values = []\n",
    "\n",
    "# Looping untuk mengekstrak data\n",
    "for metrics in data:\n",
    "    # Pastikan ada key yang dibutuhkan\n",
    "    if 'iteration' in metrics:\n",
    "        iterations.append(metrics['iteration'])\n",
    "    if 'loss_cls' in metrics:\n",
    "        loss_cls_values.append(metrics['loss_cls'])\n",
    "    if 'loss_box_reg' in metrics:\n",
    "        loss_box_reg_values.append(metrics['loss_box_reg'])\n",
    "\n",
    "# Pastikan panjang data sama, dan jika tidak, sesuaikan panjangnya\n",
    "min_len = min(len(iterations), len(loss_cls_values), len(loss_box_reg_values))\n",
    "\n",
    "# Potong data agar memiliki panjang yang sama\n",
    "iterations = iterations[:min_len]\n",
    "loss_cls_values = loss_cls_values[:min_len]\n",
    "loss_box_reg_values = loss_box_reg_values[:min_len]\n",
    "\n",
    "# Membuat plot jika data ada\n",
    "if iterations and loss_cls_values and loss_box_reg_values:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot Loss Klasifikasi\n",
    "    plt.plot(iterations, loss_cls_values, label='Loss Klasifikasi', color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "    # Plot Loss Regresi Batas\n",
    "    plt.plot(iterations, loss_box_reg_values, label='Loss Regresi Batas', color='green', linestyle='-', linewidth=2)\n",
    "\n",
    "    # Menambahkan label dan judul\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Klasifikasi dan Loss Regresi Batas selama Iterasi')\n",
    "\n",
    "    # Menambahkan legend\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    # Menampilkan grid\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Menampilkan grafik\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Data tidak lengkap, pastikan key 'loss_cls' dan 'loss_box_reg' ada dalam setiap entri.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PZDnKlV2gsV"
   },
   "source": [
    "# **Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1749972318863,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "QOHOgp0k_Lif"
   },
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    box: [xmin, ymin, xmax, ymax]\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x1g, y1g, x2g, y2g = box2\n",
    "\n",
    "    xi1 = max(x1, x1g)\n",
    "    yi1 = max(y1, y1g)\n",
    "    xi2 = min(x2, x2g)\n",
    "    yi2 = min(y2, y2g)\n",
    "    inter_area = max(xi2 - xi1, 0) * max(yi2 - yi1, 0)\n",
    "\n",
    "    box1_area = (x2 - x1) * (y2 - y1)\n",
    "    box2_area = (x2g - x1g) * (y2g - y1g)\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "    if union_area == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return inter_area / union_area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "executionInfo": {
     "elapsed": 19978,
     "status": "ok",
     "timestamp": 1749973541062,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "PEd5PqMn_OQU",
    "outputId": "2c1feb1d-3b53-4470-f9bc-6803900c46ba"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# üß† Load model\n",
    "# cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"best_model.pth\")\n",
    "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_SGD/best_model.pth\"\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# üìö Prepare dataset paths\n",
    "test_image_dir = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Dataset/dataset_new/test\"\n",
    "coco_annotation_path = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Dataset/dataset_new/test/_annotations.coco.json\"\n",
    "\n",
    "# Load COCO ground truth\n",
    "with open(coco_annotation_path) as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# Build image_id to filename mapping\n",
    "id_to_filename = {img['id']: img['file_name'] for img in coco_data['images']}\n",
    "\n",
    "# Build annotations mapping\n",
    "annotations = coco_data['annotations']\n",
    "gt_dict = {}  # {filename: (boxes, labels)}\n",
    "\n",
    "for ann in annotations:\n",
    "    image_id = ann['image_id']\n",
    "    filename = id_to_filename[image_id]\n",
    "    bbox = ann['bbox']  # [x, y, width, height]\n",
    "    category_id = ann['category_id']\n",
    "\n",
    "    if filename not in gt_dict:\n",
    "        gt_dict[filename] = {'boxes': [], 'labels': []}\n",
    "\n",
    "    # Convert bbox format to [xmin, ymin, xmax, ymax]\n",
    "    xmin, ymin, w, h = bbox\n",
    "    xmax = xmin + w\n",
    "    ymax = ymin + h\n",
    "\n",
    "    gt_dict[filename]['boxes'].append([xmin, ymin, xmax, ymax])\n",
    "    gt_dict[filename]['labels'].append(category_id)\n",
    "\n",
    "# Build category_id to class_name mapping\n",
    "category_id_to_name = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
    "class_names = [category_id_to_name[i] for i in sorted(category_id_to_name.keys())]\n",
    "\n",
    "# üî• Start evaluating\n",
    "y_true = []\n",
    "y_pred = []\n",
    "iou_threshold = 0.5\n",
    "confidence_threshold = 0.5\n",
    "\n",
    "test_images = sorted(os.listdir(test_image_dir))\n",
    "test_images = [img for img in test_images if img.endswith('.jpg') or img.endswith('.png')]\n",
    "\n",
    "for img_file in tqdm(test_images, desc=\"Processing Test Images\"):\n",
    "    # Read image\n",
    "    img_path = os.path.join(test_image_dir, img_file)\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    if img_file not in gt_dict:\n",
    "        continue  # skip images without ground truth\n",
    "\n",
    "    gt_boxes = np.array(gt_dict[img_file]['boxes'])\n",
    "    gt_classes = np.array(gt_dict[img_file]['labels'])\n",
    "\n",
    "    # Predict\n",
    "    outputs = predictor(img)\n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "\n",
    "    pred_boxes = instances.pred_boxes.tensor.numpy()\n",
    "    pred_classes = instances.pred_classes.numpy()\n",
    "    pred_scores = instances.scores.numpy()\n",
    "\n",
    "    # Filter predictions by confidence\n",
    "    keep = pred_scores > confidence_threshold\n",
    "    pred_boxes = pred_boxes[keep]\n",
    "    pred_classes = pred_classes[keep]\n",
    "\n",
    "    matched_gt = set()\n",
    "\n",
    "    # Matching predicted boxes to ground truth boxes\n",
    "    for pred_box, pred_class in zip(pred_boxes, pred_classes):\n",
    "        best_iou = 0\n",
    "        best_idx = -1\n",
    "        for idx, gt_box in enumerate(gt_boxes):\n",
    "            iou = calculate_iou(pred_box, gt_box)\n",
    "            if iou > best_iou and idx not in matched_gt:\n",
    "                best_iou = iou\n",
    "                best_idx = idx\n",
    "        if best_iou >= iou_threshold and best_idx != -1:\n",
    "            y_true.append(gt_classes[best_idx])\n",
    "            y_pred.append(pred_class)\n",
    "            matched_gt.add(best_idx)\n",
    "        else:\n",
    "            # False positive\n",
    "            y_true.append(-1)  # background\n",
    "            y_pred.append(pred_class)\n",
    "\n",
    "    # False negatives\n",
    "    for idx, gt_class in enumerate(gt_classes):\n",
    "        if idx not in matched_gt:\n",
    "            y_true.append(gt_class)\n",
    "            y_pred.append(-1)\n",
    "\n",
    "# üî• Build Confusion Matrix\n",
    "all_labels = sorted(list(set([lab for lab in y_true if lab != -1] + [lab for lab in y_pred if lab != -1])))\n",
    "cm = confusion_matrix(y_true, y_pred, labels=all_labels)\n",
    "\n",
    "class_labels = [category_id_to_name[i] for i in all_labels]\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix - RetinaNet Detectron2 (COCO Format)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0Z5g0Rb2nEd"
   },
   "source": [
    "# **Evaluasi Data Train, Validation, dan Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 168415,
     "status": "ok",
     "timestamp": 1749972608245,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "tQIaZijbfB9G",
    "outputId": "839a4dd9-39d7-41b5-893d-ffc67e1f43d1"
   },
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.modeling import build_model\n",
    "\n",
    "# Load config dan model\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_SGD/config.yaml\")\n",
    "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_SGD/best_model.pth\"\n",
    "cfg.MODEL.DEVICE = 'cuda'  # atau 'cpu'\n",
    "cfg.DATASETS.TEST = (\"roboflow_train\",)\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.5\n",
    "\n",
    "evaluator = COCOEvaluator(\"roboflow_train\", cfg, False, output_dir=\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_SGD/eval_train\")\n",
    "val_loader = build_detection_test_loader(cfg, \"roboflow_train\")\n",
    "\n",
    "model = build_model(cfg)\n",
    "DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)\n",
    "\n",
    "results = inference_on_dataset(model, val_loader, evaluator)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24635,
     "status": "ok",
     "timestamp": 1749972676675,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "NE8yRpaWkpn-",
    "outputId": "d11c4771-9b02-48b1-ea6d-524ebedb74d2"
   },
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.modeling import build_model\n",
    "\n",
    "# Load config dan model\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_SGD/config.yaml\")\n",
    "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_SGD/best_model.pth\"\n",
    "cfg.MODEL.DEVICE = 'cuda'  # atau 'cpu'\n",
    "cfg.DATASETS.TEST = (\"roboflow_val\",)\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.5\n",
    "\n",
    "evaluator = COCOEvaluator(\"roboflow_val\", cfg, False, output_dir=\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_SGD/eval_val\")\n",
    "val_loader = build_detection_test_loader(cfg, \"roboflow_val\")\n",
    "\n",
    "model = build_model(cfg)\n",
    "DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)\n",
    "\n",
    "results = inference_on_dataset(model, val_loader, evaluator)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16809,
     "status": "ok",
     "timestamp": 1749972822867,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "2rnKb-RLX8Ls",
    "outputId": "b511db0a-063d-4483-9b06-3eeac7306727"
   },
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.modeling import build_model\n",
    "\n",
    "# Load config dan model\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_SGD/config.yaml\")\n",
    "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_SGD/best_model.pth\"\n",
    "cfg.MODEL.DEVICE = 'cuda'  # atau 'cpu'\n",
    "cfg.DATASETS.TEST = (\"roboflow_test\",)\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.5\n",
    "\n",
    "evaluator = COCOEvaluator(\"roboflow_test\", cfg, False, output_dir=\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_SGD/eval_val\")\n",
    "val_loader = build_detection_test_loader(cfg, \"roboflow_test\")\n",
    "\n",
    "model = build_model(cfg)\n",
    "DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)\n",
    "\n",
    "results = inference_on_dataset(model, val_loader, evaluator)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1749973363120,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "qJ5AuVa6g9LA"
   },
   "outputs": [],
   "source": [
    "from detectron2.evaluation.evaluator import DatasetEvaluator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class PRF1Evaluator(DatasetEvaluator):\n",
    "    def __init__(self, dataset_name, metadata=None, class_names=None):\n",
    "        from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "        self.metadata = MetadataCatalog.get(dataset_name)\n",
    "        self.dataset_dicts = DatasetCatalog.get(dataset_name)\n",
    "        self.class_names = class_names if class_names else self.metadata.thing_classes\n",
    "        self.gts = []\n",
    "        self.preds = []\n",
    "\n",
    "        # Mapping image_id ke ground truth\n",
    "        self.imgid_to_gt = {}\n",
    "        for data in self.dataset_dicts:\n",
    "            gt_classes = [ann[\"category_id\"] for ann in data[\"annotations\"]]\n",
    "            self.imgid_to_gt[data[\"image_id\"]] = gt_classes\n",
    "\n",
    "    def reset(self):\n",
    "        self.gts = []\n",
    "        self.preds = []\n",
    "\n",
    "    def process(self, inputs, outputs):\n",
    "        for input, output in zip(inputs, outputs):\n",
    "            img_id = input[\"image_id\"]\n",
    "            gt_classes = self.imgid_to_gt.get(img_id, [])\n",
    "            pred_classes = output[\"instances\"].pred_classes.cpu().numpy() if len(output[\"instances\"]) > 0 else []\n",
    "\n",
    "            # Samakan panjang GT dan prediksi\n",
    "            if len(pred_classes) < len(gt_classes):\n",
    "                pred_classes = list(pred_classes) + [-1] * (len(gt_classes) - len(pred_classes))\n",
    "            elif len(pred_classes) > len(gt_classes):\n",
    "                pred_classes = pred_classes[:len(gt_classes)]\n",
    "\n",
    "            # Buang ID invalid (< 1)\n",
    "            filtered = [\n",
    "                (g, p) for g, p in zip(gt_classes, pred_classes)\n",
    "                if g > 0 and p > 0\n",
    "            ]\n",
    "\n",
    "            if filtered:\n",
    "                g_filtered, p_filtered = zip(*filtered)\n",
    "                self.gts.extend(g_filtered)\n",
    "                self.preds.extend(p_filtered)\n",
    "\n",
    "    def evaluate(self):\n",
    "        print(\"\\n==== Precision, Recall, and F1-Score per Class ====\\n\")\n",
    "\n",
    "        if not self.gts or not self.preds:\n",
    "            print(\"‚ö†Ô∏è Tidak ada ground truth atau prediksi yang valid untuk dievaluasi.\")\n",
    "            return {}\n",
    "\n",
    "        # Shift kelas agar dimulai dari 0 (untuk sklearn)\n",
    "        y_true = [y - 1 for y in self.gts]\n",
    "        y_pred = [y - 1 for y in self.preds]\n",
    "\n",
    "        num_classes = len(self.class_names)\n",
    "\n",
    "        # Hitung classification report dengan penyesuaian jumlah label\n",
    "        report_dict = classification_report(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            labels=list(range(num_classes)),\n",
    "            target_names=self.class_names,\n",
    "            output_dict=True,\n",
    "            digits=3,\n",
    "            zero_division=0\n",
    "        )\n",
    "\n",
    "        # Konversi ke DataFrame\n",
    "        df = pd.DataFrame(report_dict).transpose()\n",
    "        df.index.name = 'Class'\n",
    "\n",
    "        # Ambil akurasi\n",
    "        accuracy = report_dict.get(\"accuracy\", None)\n",
    "        if \"accuracy\" in df.index:\n",
    "            df.drop(\"accuracy\", inplace=True)\n",
    "\n",
    "        if 'support' in df.columns:\n",
    "            df['support'] = df['support'].astype(int)\n",
    "\n",
    "        df = df[['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "        # Cetak\n",
    "        print(df.to_string(float_format=\"%.3f\"))\n",
    "        if accuracy is not None:\n",
    "            print(f\"\\nOverall Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "        # (Opsional) Tampilkan confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(pd.DataFrame(cm, index=self.class_names, columns=self.class_names))\n",
    "\n",
    "        return {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"classification_report\": df,\n",
    "            \"confusion_matrix\": cm\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69674,
     "status": "ok",
     "timestamp": 1749973435725,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "Aou9k3hmhANy",
    "outputId": "0903e9d8-2130-4800-f1f2-25d88adc0575"
   },
   "outputs": [],
   "source": [
    "# Setup config\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_SGD/config.yaml\")\n",
    "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_SGD/best_model.pth\"\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.5\n",
    "cfg.MODEL.DEVICE = 'cuda'\n",
    "cfg.DATASETS.TEST = (\"roboflow_train\",)\n",
    "\n",
    "class_names = [\"Cardiomegaly\", \"Nodule/Mass\", \"Pneumothorax\"]\n",
    "\n",
    "evaluator = PRF1Evaluator(\n",
    "    \"roboflow_train\",\n",
    "    class_names=class_names\n",
    ")\n",
    "\n",
    "test_loader = build_detection_test_loader(cfg, \"roboflow_train\")\n",
    "inference_on_dataset(model, test_loader, evaluator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8678,
     "status": "ok",
     "timestamp": 1749973469674,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "gibMQYxEhGST",
    "outputId": "20f7783c-0872-41b9-b283-bd7107e23ec0"
   },
   "outputs": [],
   "source": [
    "# Setup config\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_SGD/config.yaml\")\n",
    "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_SGD/best_model.pth\"\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.5\n",
    "cfg.MODEL.DEVICE = 'cuda'\n",
    "cfg.DATASETS.TEST = (\"roboflow_val\",)\n",
    "\n",
    "class_names = [\"Cardiomegaly\", \"Nodule/Mass\", \"Pneumothorax\"]\n",
    "\n",
    "evaluator = PRF1Evaluator(\n",
    "    \"roboflow_val\",\n",
    "    class_names=class_names\n",
    ")\n",
    "\n",
    "test_loader = build_detection_test_loader(cfg, \"roboflow_val\")\n",
    "inference_on_dataset(model, test_loader, evaluator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8771,
     "status": "ok",
     "timestamp": 1749973496454,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "-GOvp-pchLti",
    "outputId": "ce7b7892-c420-4fe4-c6e8-d1869442ce1b"
   },
   "outputs": [],
   "source": [
    "# Setup config\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_SGD/config.yaml\")\n",
    "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_SGD/best_model.pth\"\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.5\n",
    "cfg.MODEL.DEVICE = 'cuda'\n",
    "cfg.DATASETS.TEST = (\"roboflow_test\",)\n",
    "\n",
    "class_names = [\"Cardiomegaly\", \"Nodule/Mass\", \"Pneumothorax\"]\n",
    "\n",
    "evaluator = PRF1Evaluator(\n",
    "    \"roboflow_test\",\n",
    "    class_names=class_names\n",
    ")\n",
    "\n",
    "test_loader = build_detection_test_loader(cfg, \"roboflow_test\")\n",
    "inference_on_dataset(model, test_loader, evaluator)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPEFb5w4z1NKNHRZWtEsbob",
   "gpuType": "T4",
   "machine_shape": "hm",
   "mount_file_id": "1XK4hLsmfVkQay9aIxhfqxNzFIj15jKdd",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
