{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUCTZRwusn7k"
   },
   "source": [
    "# **Install Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 276341,
     "status": "ok",
     "timestamp": 1750001849906,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "wqME7bLtRSuy",
    "outputId": "3315552d-cdb6-4fa5-cf8a-1f283223dc25"
   },
   "outputs": [],
   "source": [
    "# ðŸ“¦ Install dependencies\n",
    "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
    "!pip install -q pycocotools\n",
    "\n",
    "# ðŸ”§ Setup: Import\n",
    "import os\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "import random\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nSq1txlswB0"
   },
   "source": [
    "# **Register Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5440,
     "status": "ok",
     "timestamp": 1750001900074,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "m5A69KAiTI-D",
    "outputId": "324cb764-c8f4-4700-9522-df7b2470ef9c"
   },
   "outputs": [],
   "source": [
    "# Set root folder di Google Drive\n",
    "dataset_root = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Dataset/dataset_new\"\n",
    "\n",
    "# Buat path lengkap ke JSON dan folder gambar\n",
    "train_json = os.path.join(dataset_root, \"train/_annotations.coco.json\")\n",
    "val_json = os.path.join(dataset_root, \"valid/_annotations.coco.json\")\n",
    "test_json = os.path.join(dataset_root, \"test/_annotations.coco.json\")\n",
    "train_img_dir = os.path.join(dataset_root, \"train\")\n",
    "val_img_dir = os.path.join(dataset_root, \"valid\")\n",
    "test_img_dir = os.path.join(dataset_root, \"test\")\n",
    "\n",
    "# âœ… Cek apakah file dan folder ada\n",
    "print(\"Train JSON exists:\", os.path.exists(train_json))\n",
    "print(\"Train Image Dir exists:\", os.path.exists(train_img_dir))\n",
    "\n",
    "# ðŸ—‚ Daftarkan dataset ke Detectron2\n",
    "register_coco_instances(\"roboflow_train\", {}, train_json, train_img_dir)\n",
    "register_coco_instances(\"roboflow_val\", {}, val_json, val_img_dir)\n",
    "register_coco_instances(\"roboflow_test\", {}, test_json, test_img_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExP8iZJWNIKz"
   },
   "source": [
    "# Epoch 30_1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 221,
     "status": "ok",
     "timestamp": 1749909599219,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "cD_6pzKzTSUq",
    "outputId": "e883b5d8-5fa4-4ef9-e766-8e30a764181a"
   },
   "outputs": [],
   "source": [
    "from detectron2 import model_zoo\n",
    "\n",
    "# âš™ï¸ Konfigurasi RetinaNet\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"roboflow_train\",)\n",
    "cfg.DATASETS.TEST = (\"roboflow_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "\n",
    "cfg.MODEL.WEIGHTS = \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
    "cfg.SOLVER.IMS_PER_BATCH = 16\n",
    "cfg.SOLVER.BASE_LR = 0.001  # Untuk Adam, bisa 1e-3 â€“ 1e-4\n",
    "cfg.SOLVER.MAX_ITER = 1680  # Ubah sesuai jumlah data dan epoch yang diinginkan\n",
    "cfg.SOLVER.STEPS = []  # Jangan gunakan step scheduler untuk Adam\n",
    "cfg.SOLVER.WEIGHT_DECAY = 0.0001\n",
    "cfg.SOLVER.WEIGHT_DECAY_BIAS = 0.0\n",
    "cfg.SOLVER.WEIGHT_DECAY_NORM = 0.0  # Tambahan penting\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 500  # Evaluasi setiap 500 iterasi\n",
    "cfg.MODEL.RETINANET.NUM_CLASSES = 4  # Jumlah kelas sebenarnya (tanpa background)\n",
    "\n",
    "# ðŸ“‚ Output directory\n",
    "cfg.OUTPUT_DIR = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_1e-3_Adam\"\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1647010,
     "status": "error",
     "timestamp": 1749911258281,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "1ezo2Wc7TiVm",
    "outputId": "b82559dc-bf70-4425-c55a-b223653fe526"
   },
   "outputs": [],
   "source": [
    "from detectron2.engine.hooks import BestCheckpointer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.utils.events import EventStorage\n",
    "\n",
    "import torch\n",
    "\n",
    "# ðŸ§  Custom Trainer class\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "\n",
    "    @classmethod\n",
    "    def build_optimizer(cls, cfg, model):\n",
    "        \"\"\"\n",
    "        Override default SGD optimizer with Adam\n",
    "        \"\"\"\n",
    "        params = []\n",
    "        for name, param in model.named_parameters():\n",
    "            if not param.requires_grad:\n",
    "                continue\n",
    "            lr = cfg.SOLVER.BASE_LR\n",
    "            if \"bias\" in name:\n",
    "                weight_decay = cfg.SOLVER.WEIGHT_DECAY_BIAS\n",
    "            elif \"norm\" in name:\n",
    "                weight_decay = cfg.SOLVER.WEIGHT_DECAY_NORM  # Tambahkan decay norm\n",
    "            else:\n",
    "                weight_decay = cfg.SOLVER.WEIGHT_DECAY\n",
    "            params.append({\"params\": [param], \"lr\": lr, \"weight_decay\": weight_decay})\n",
    "\n",
    "        optimizer = torch.optim.Adam(params, lr=cfg.SOLVER.BASE_LR)\n",
    "        return optimizer\n",
    "\n",
    "    def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        hooks.insert(\n",
    "            -1,\n",
    "            BestCheckpointer(\n",
    "                cfg.TEST.EVAL_PERIOD,\n",
    "                checkpointer=DetectionCheckpointer(self.model, cfg.OUTPUT_DIR),\n",
    "                val_metric=\"bbox/AP\",\n",
    "                mode=\"max\",\n",
    "                file_prefix=\"best_model\"\n",
    "            )\n",
    "        )\n",
    "        return hooks\n",
    "\n",
    "# Inisialisasi trainer dan mulai training\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUTxr5VwNP44"
   },
   "source": [
    "# Epoch 30_1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 414,
     "status": "ok",
     "timestamp": 1750001903552,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "VQY07qQGNT4L",
    "outputId": "54c85f7e-0b77-4a88-e37c-46e306fab8e4"
   },
   "outputs": [],
   "source": [
    "from detectron2 import model_zoo\n",
    "\n",
    "# âš™ï¸ Konfigurasi RetinaNet\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"roboflow_train\",)\n",
    "cfg.DATASETS.TEST = (\"roboflow_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "\n",
    "cfg.MODEL.WEIGHTS = \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
    "cfg.SOLVER.IMS_PER_BATCH = 16\n",
    "cfg.SOLVER.BASE_LR = 0.00001\n",
    "cfg.SOLVER.MAX_ITER = 1680  # Ubah sesuai jumlah data dan epoch yang diinginkan\n",
    "cfg.SOLVER.STEPS = []  # Jangan gunakan step scheduler untuk Adam\n",
    "cfg.SOLVER.WEIGHT_DECAY = 0.0001\n",
    "cfg.SOLVER.WEIGHT_DECAY_BIAS = 0.0\n",
    "# cfg.SOLVER.WEIGHT_DECAY_NORM = 0.0  # Tambahan penting\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 500  # Evaluasi setiap 500 iterasi\n",
    "cfg.MODEL.RETINANET.NUM_CLASSES = 4  # Jumlah kelas sebenarnya (tanpa background)\n",
    "\n",
    "# ðŸ“‚ Output directory\n",
    "cfg.OUTPUT_DIR = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_1e-5_Adam\"\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4005596,
     "status": "ok",
     "timestamp": 1749959747577,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "uTOxOJbqNZbT",
    "outputId": "2d57bc61-a140-44d9-e162-52a33e447374"
   },
   "outputs": [],
   "source": [
    "from detectron2.engine.hooks import BestCheckpointer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.utils.events import EventStorage\n",
    "\n",
    "import torch\n",
    "\n",
    "# ðŸ§  Custom Trainer class\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "\n",
    "    @classmethod\n",
    "    def build_optimizer(cls, cfg, model):\n",
    "        \"\"\"\n",
    "        Override default SGD optimizer with Adam\n",
    "        \"\"\"\n",
    "        params = []\n",
    "        for name, param in model.named_parameters():\n",
    "            if not param.requires_grad:\n",
    "                continue\n",
    "            lr = cfg.SOLVER.BASE_LR\n",
    "            if \"bias\" in name:\n",
    "                weight_decay = cfg.SOLVER.WEIGHT_DECAY_BIAS\n",
    "            elif \"norm\" in name:\n",
    "                weight_decay = cfg.SOLVER.WEIGHT_DECAY_NORM  # Tambahkan decay norm\n",
    "            else:\n",
    "                weight_decay = cfg.SOLVER.WEIGHT_DECAY\n",
    "            params.append({\"params\": [param], \"lr\": lr, \"weight_decay\": weight_decay})\n",
    "\n",
    "        optimizer = torch.optim.Adam(params, lr=cfg.SOLVER.BASE_LR)\n",
    "        return optimizer\n",
    "\n",
    "    def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        hooks.insert(\n",
    "            -1,\n",
    "            BestCheckpointer(\n",
    "                cfg.TEST.EVAL_PERIOD,\n",
    "                checkpointer=DetectionCheckpointer(self.model, cfg.OUTPUT_DIR),\n",
    "                val_metric=\"bbox/AP\",\n",
    "                mode=\"max\",\n",
    "                file_prefix=\"best_model\"\n",
    "            )\n",
    "        )\n",
    "        return hooks\n",
    "\n",
    "# Inisialisasi trainer dan mulai training\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lxrOlSyv68H"
   },
   "source": [
    "**Save Konfigurasi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sH4JTx-Jq9YM"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(cfg.OUTPUT_DIR, \"config.yaml\"), \"w\") as f:\n",
    "    f.write(cfg.dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9P_vq-wv3ze"
   },
   "source": [
    "**Test Prediksi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 890
    },
    "executionInfo": {
     "elapsed": 3224,
     "status": "ok",
     "timestamp": 1749959767846,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "OLkOF_U2rCHw",
    "outputId": "0a37fd7b-c977-4079-a1e5-445105da6764"
   },
   "outputs": [],
   "source": [
    "# ðŸ§  Load the trained model\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"best_model.pth\")  # Load the weights from your training\n",
    "#cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Set threshold to 50% for detection\n",
    "\n",
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# ðŸ“¸ Read the image\n",
    "#image_path = '/content/valid/00000732_005_jpg.rf.3541c4c659fec2d5d003b4fb7a380dea.jpg'\n",
    "image_path = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Dataset/test/9ed1f91369552618456da255b02820b3_jpg.rf.17cd671024249e0b1f3a9e36be41a928.jpg\"\n",
    "im = cv2.imread(image_path)\n",
    "\n",
    "# ðŸ§  Run inference\n",
    "outputs = predictor(im)\n",
    "\n",
    "# Filter instances with confidence\n",
    "confidence = 0.5\n",
    "instances = outputs[\"instances\"]\n",
    "scores = instances.scores\n",
    "filtered_instances = instances[scores > confidence]\n",
    "\n",
    "# ðŸ–¼ï¸ Visualize the results\n",
    "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(\"roboflow_train\"), scale=1)\n",
    "v = v.draw_instance_predictions(filtered_instances.to(\"cpu\"))\n",
    "\n",
    "# Show the image with filtered instances\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(v.get_image())\n",
    "plt.show()\n",
    "\n",
    "# Optionally, print out the number of detections\n",
    "print(f\"Detected {len(filtered_instances)} objects with confidence > {confidence*100}%.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQY_Y4favsS_"
   },
   "source": [
    "**Confusion Matriks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 75,
     "status": "ok",
     "timestamp": 1750001914750,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "XG-J-HOwvkZq"
   },
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    box: [xmin, ymin, xmax, ymax]\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x1g, y1g, x2g, y2g = box2\n",
    "\n",
    "    xi1 = max(x1, x1g)\n",
    "    yi1 = max(y1, y1g)\n",
    "    xi2 = min(x2, x2g)\n",
    "    yi2 = min(y2, y2g)\n",
    "    inter_area = max(xi2 - xi1, 0) * max(yi2 - yi1, 0)\n",
    "\n",
    "    box1_area = (x2 - x1) * (y2 - y1)\n",
    "    box2_area = (x2g - x1g) * (y2g - y1g)\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "    if union_area == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return inter_area / union_area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "executionInfo": {
     "elapsed": 17466,
     "status": "ok",
     "timestamp": 1750001944002,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "Hn8AQHTNvpnv",
    "outputId": "2bab1dd3-5eef-41d0-dc35-e67eba77d974"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# ðŸ§  Load model\n",
    "# cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"best_model.pth\")\n",
    "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_1e-5_Adam/best_model.pth\"\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# ðŸ“š Prepare dataset paths\n",
    "test_image_dir = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Dataset/dataset_new/test\"\n",
    "coco_annotation_path = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Dataset/dataset_new/test/_annotations.coco.json\"\n",
    "\n",
    "# Load COCO ground truth\n",
    "with open(coco_annotation_path) as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# Build image_id to filename mapping\n",
    "id_to_filename = {img['id']: img['file_name'] for img in coco_data['images']}\n",
    "\n",
    "# Build annotations mapping\n",
    "annotations = coco_data['annotations']\n",
    "gt_dict = {}  # {filename: (boxes, labels)}\n",
    "\n",
    "for ann in annotations:\n",
    "    image_id = ann['image_id']\n",
    "    filename = id_to_filename[image_id]\n",
    "    bbox = ann['bbox']  # [x, y, width, height]\n",
    "    category_id = ann['category_id']\n",
    "\n",
    "    if filename not in gt_dict:\n",
    "        gt_dict[filename] = {'boxes': [], 'labels': []}\n",
    "\n",
    "    # Convert bbox format to [xmin, ymin, xmax, ymax]\n",
    "    xmin, ymin, w, h = bbox\n",
    "    xmax = xmin + w\n",
    "    ymax = ymin + h\n",
    "\n",
    "    gt_dict[filename]['boxes'].append([xmin, ymin, xmax, ymax])\n",
    "    gt_dict[filename]['labels'].append(category_id)\n",
    "\n",
    "# Build category_id to class_name mapping\n",
    "category_id_to_name = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
    "class_names = [category_id_to_name[i] for i in sorted(category_id_to_name.keys())]\n",
    "\n",
    "# ðŸ”¥ Start evaluating\n",
    "y_true = []\n",
    "y_pred = []\n",
    "iou_threshold = 0.5\n",
    "confidence_threshold = 0.5\n",
    "\n",
    "test_images = sorted(os.listdir(test_image_dir))\n",
    "test_images = [img for img in test_images if img.endswith('.jpg') or img.endswith('.png')]\n",
    "\n",
    "for img_file in tqdm(test_images, desc=\"Processing Test Images\"):\n",
    "    # Read image\n",
    "    img_path = os.path.join(test_image_dir, img_file)\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    if img_file not in gt_dict:\n",
    "        continue  # skip images without ground truth\n",
    "\n",
    "    gt_boxes = np.array(gt_dict[img_file]['boxes'])\n",
    "    gt_classes = np.array(gt_dict[img_file]['labels'])\n",
    "\n",
    "    # Predict\n",
    "    outputs = predictor(img)\n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "\n",
    "    pred_boxes = instances.pred_boxes.tensor.numpy()\n",
    "    pred_classes = instances.pred_classes.numpy()\n",
    "    pred_scores = instances.scores.numpy()\n",
    "\n",
    "    # Filter predictions by confidence\n",
    "    keep = pred_scores > confidence_threshold\n",
    "    pred_boxes = pred_boxes[keep]\n",
    "    pred_classes = pred_classes[keep]\n",
    "\n",
    "    matched_gt = set()\n",
    "\n",
    "    # Matching predicted boxes to ground truth boxes\n",
    "    for pred_box, pred_class in zip(pred_boxes, pred_classes):\n",
    "        best_iou = 0\n",
    "        best_idx = -1\n",
    "        for idx, gt_box in enumerate(gt_boxes):\n",
    "            iou = calculate_iou(pred_box, gt_box)\n",
    "            if iou > best_iou and idx not in matched_gt:\n",
    "                best_iou = iou\n",
    "                best_idx = idx\n",
    "        if best_iou >= iou_threshold and best_idx != -1:\n",
    "            y_true.append(gt_classes[best_idx])\n",
    "            y_pred.append(pred_class)\n",
    "            matched_gt.add(best_idx)\n",
    "        else:\n",
    "            # False positive\n",
    "            y_true.append(-1)  # background\n",
    "            y_pred.append(pred_class)\n",
    "\n",
    "    # False negatives\n",
    "    for idx, gt_class in enumerate(gt_classes):\n",
    "        if idx not in matched_gt:\n",
    "            y_true.append(gt_class)\n",
    "            y_pred.append(-1)\n",
    "\n",
    "# ðŸ”¥ Build Confusion Matrix\n",
    "all_labels = sorted(list(set([lab for lab in y_true if lab != -1] + [lab for lab in y_pred if lab != -1])))\n",
    "cm = confusion_matrix(y_true, y_pred, labels=all_labels)\n",
    "\n",
    "class_labels = [category_id_to_name[i] for i in all_labels]\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix - RetinaNet Detectron2 (COCO Format)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OftwEbcBvyZp"
   },
   "source": [
    "**Evaluasi Data Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3295876,
     "status": "ok",
     "timestamp": 1749963137894,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "wap6fWODu91S",
    "outputId": "d39e5a17-d1b7-4489-8ff3-edaa17d559f5"
   },
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.modeling import build_model\n",
    "\n",
    "# Load config dan model\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_1e-5_Adam/config.yaml\")\n",
    "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_1e-5_Adam/best_model.pth\"\n",
    "cfg.MODEL.DEVICE = 'cpu'  # atau 'cpu'\n",
    "cfg.DATASETS.TEST = (\"roboflow_train\",)\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.5\n",
    "\n",
    "evaluator = COCOEvaluator(\"roboflow_train\", cfg, False, output_dir=\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_1e-5_Adam/eval_train\")\n",
    "val_loader = build_detection_test_loader(cfg, \"roboflow_train\")\n",
    "\n",
    "model = build_model(cfg)\n",
    "DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)\n",
    "\n",
    "results = inference_on_dataset(model, val_loader, evaluator)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbUteOakwLjK"
   },
   "source": [
    "**Evaluasi Data Validasi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 399497,
     "status": "ok",
     "timestamp": 1749963562123,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "dtxjK3YVwKjl",
    "outputId": "3ef6f070-3daf-4536-9829-707209af34fe"
   },
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.modeling import build_model\n",
    "\n",
    "# Load config dan model\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_1e-5_Adam/config.yaml\")\n",
    "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_1e-5_Adam/best_model.pth\"\n",
    "cfg.MODEL.DEVICE = 'cpu'  # atau 'cpu'\n",
    "cfg.DATASETS.TEST = (\"roboflow_val\",)\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.5\n",
    "\n",
    "evaluator = COCOEvaluator(\"roboflow_val\", cfg, False, output_dir=\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_1e-5_Adam/eval_valid\")\n",
    "val_loader = build_detection_test_loader(cfg, \"roboflow_val\")\n",
    "\n",
    "model = build_model(cfg)\n",
    "DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)\n",
    "\n",
    "results = inference_on_dataset(model, val_loader, evaluator)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZISGwDxwOc3"
   },
   "source": [
    "**Evaluasi Data Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 384912,
     "status": "ok",
     "timestamp": 1749964072058,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "WiE_zn6TwVVw",
    "outputId": "c85c7470-606a-445f-980a-d1bda1ba26bb"
   },
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.modeling import build_model\n",
    "\n",
    "# Load config dan model\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_1e-5_Adam/config.yaml\")\n",
    "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_1e-5_Adam/best_model.pth\"\n",
    "cfg.MODEL.DEVICE = 'cpu'  # atau 'cpu'\n",
    "cfg.DATASETS.TEST = (\"roboflow_test\",)\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.5\n",
    "\n",
    "evaluator = COCOEvaluator(\"roboflow_test\", cfg, False, output_dir=\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_1e-5_Adam/eval_test\")\n",
    "val_loader = build_detection_test_loader(cfg, \"roboflow_test\")\n",
    "\n",
    "model = build_model(cfg)\n",
    "DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)\n",
    "\n",
    "results = inference_on_dataset(model, val_loader, evaluator)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEZbg2Fewhye"
   },
   "source": [
    "**Evaluasi Precision Recall F1-Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MWdT7xqbwnDF"
   },
   "outputs": [],
   "source": [
    "from detectron2.evaluation.evaluator import DatasetEvaluator\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class PRF1Evaluator(DatasetEvaluator):\n",
    "    def __init__(self, dataset_name, metadata, class_names=None):\n",
    "        from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "        self.metadata = MetadataCatalog.get(dataset_name)\n",
    "        self.dataset_dicts = DatasetCatalog.get(dataset_name)\n",
    "        self.class_names = class_names if class_names else self.metadata.thing_classes\n",
    "        self.gts = []\n",
    "        self.preds = []\n",
    "\n",
    "        # Buat mapping image_id ke daftar ground truth class ID\n",
    "        self.imgid_to_gt = {}\n",
    "        for data in self.dataset_dicts:\n",
    "            gt_classes = [ann[\"category_id\"] for ann in data[\"annotations\"]]\n",
    "            self.imgid_to_gt[data[\"image_id\"]] = gt_classes\n",
    "\n",
    "    def reset(self):\n",
    "        self.gts = []\n",
    "        self.preds = []\n",
    "\n",
    "    def process(self, inputs, outputs):\n",
    "        for input, output in zip(inputs, outputs):\n",
    "            img_id = input[\"image_id\"]\n",
    "            gt_classes = self.imgid_to_gt.get(img_id, [])\n",
    "            pred_classes = output[\"instances\"].pred_classes.cpu().numpy() if len(output[\"instances\"]) > 0 else []\n",
    "\n",
    "            # Samakan panjang prediksi dan ground truth\n",
    "            if len(pred_classes) < len(gt_classes):\n",
    "                pred_classes = list(pred_classes) + [-1] * (len(gt_classes) - len(pred_classes))\n",
    "            elif len(pred_classes) > len(gt_classes):\n",
    "                pred_classes = pred_classes[:len(gt_classes)]\n",
    "\n",
    "            self.gts.extend(gt_classes)\n",
    "            self.preds.extend(pred_classes)\n",
    "\n",
    "    def evaluate(self):\n",
    "        print(\"\\n==== Precision, Recall, and F1-Score per Class ====\\n\")\n",
    "\n",
    "        # Ambil hasil sebagai dictionary\n",
    "        report_dict = classification_report(\n",
    "            self.gts,\n",
    "            self.preds,\n",
    "            target_names=self.class_names,\n",
    "            output_dict=True,\n",
    "            digits=3,\n",
    "            zero_division=0\n",
    "        )\n",
    "\n",
    "        # Konversi ke DataFrame\n",
    "        df = pd.DataFrame(report_dict).transpose()\n",
    "        df.index.name = 'Class'\n",
    "\n",
    "        # Ambil dan simpan nilai akurasi, hapus dari tabel supaya tampil rapi\n",
    "        accuracy = report_dict.get(\"accuracy\", None)\n",
    "        if \"accuracy\" in df.index:\n",
    "            df.drop(\"accuracy\", inplace=True)\n",
    "\n",
    "        # Ubah support menjadi integer\n",
    "        if 'support' in df.columns:\n",
    "            df['support'] = df['support'].astype(int)\n",
    "\n",
    "        # Urutkan kolom\n",
    "        df = df[['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "        # Cetak tabel\n",
    "        print(df.to_string(float_format=\"%.3f\"))\n",
    "\n",
    "        # Cetak akurasi secara terpisah\n",
    "        if accuracy is not None:\n",
    "            print(f\"\\nOverall Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "        # Return hanya data, tanpa tampilkan dict sebagai output Python\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITL_4S9swyT5"
   },
   "source": [
    "**Data Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70144,
     "status": "ok",
     "timestamp": 1749964228795,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "xa5PQC_swsGz",
    "outputId": "6110ba5f-7247-4109-a63e-abce06bea8d6"
   },
   "outputs": [],
   "source": [
    "class_names = [\"Cardiomegaly\", \"Nodule/Mass\", \"Pneumothorax\"]\n",
    "\n",
    "evaluator_test = PRF1Evaluator(\"roboflow_train\", cfg, class_names=class_names)\n",
    "test_loader = build_detection_test_loader(cfg, \"roboflow_train\")\n",
    "inference_on_dataset(trainer.model, test_loader, evaluator_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNzI2K_-w0Uc"
   },
   "source": [
    "**Data Validasi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8887,
     "status": "ok",
     "timestamp": 1749964293167,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "_B6VG20dws3e",
    "outputId": "bd4b4ff8-3218-4a92-eccd-6b50fa09b07e"
   },
   "outputs": [],
   "source": [
    "class_names = [\"Cardiomegaly\", \"Nodule/Mass\", \"Pneumothorax\"]\n",
    "\n",
    "evaluator_test = PRF1Evaluator(\"roboflow_val\", cfg, class_names=class_names)\n",
    "test_loader = build_detection_test_loader(cfg, \"roboflow_val\")\n",
    "inference_on_dataset(trainer.model, test_loader, evaluator_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bc7n_a7qw2rJ"
   },
   "source": [
    "**Data Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9113,
     "status": "ok",
     "timestamp": 1749964306609,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "1hu2U7dRwtjk",
    "outputId": "3d0b7e57-b3be-46e3-d44c-4d8d4ec00a1f"
   },
   "outputs": [],
   "source": [
    "class_names = [\"Cardiomegaly\", \"Nodule/Mass\", \"Pneumothorax\"]\n",
    "\n",
    "evaluator_test = PRF1Evaluator(\"roboflow_test\", cfg, class_names=class_names)\n",
    "test_loader = build_detection_test_loader(cfg, \"roboflow_test\")\n",
    "inference_on_dataset(trainer.model, test_loader, evaluator_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wakic4yzUge_"
   },
   "source": [
    "# **Konfigurasi Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1748612823926,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "on9TFOafUi0N",
    "outputId": "cba5c032-ad1e-45d0-d845-6a57ab6138e0"
   },
   "outputs": [],
   "source": [
    "import detectron2\n",
    "print(detectron2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1749911381380,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "kYy9Z2U9dDsy",
    "outputId": "fa10e1d8-45f2-4d11-ed04-c0c8b104677e"
   },
   "outputs": [],
   "source": [
    "from detectron2 import model_zoo\n",
    "\n",
    "# âš™ï¸ Konfigurasi RetinaNet\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"roboflow_train\",)\n",
    "cfg.DATASETS.TEST = (\"roboflow_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "\n",
    "cfg.MODEL.WEIGHTS = \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
    "cfg.MODEL.RETINANET.NUM_CLASSES = 4  # Jumlah kelas sebenarnya\n",
    "\n",
    "# ðŸ”§ Konfigurasi Optimizer Adam\n",
    "cfg.SOLVER.BASE_LR = 5e-5  # Stabil dan umum untuk Adam\n",
    "cfg.SOLVER.IMS_PER_BATCH = 16\n",
    "cfg.SOLVER.MAX_ITER = 1680  # Jumlah iterasi total\n",
    "cfg.SOLVER.STEPS = []  # Tidak pakai step decay\n",
    "# cfg.SOLVER.WARMUP_ITERS = 0  # Tanpa warmup\n",
    "cfg.SOLVER.WEIGHT_DECAY = 0.0001\n",
    "cfg.SOLVER.WEIGHT_DECAY_BIAS = 0.0\n",
    "# cfg.SOLVER.WEIGHT_DECAY_NORM = 0.0\n",
    "\n",
    "# ðŸ“ˆ Evaluasi setiap 500 iterasi\n",
    "cfg.TEST.EVAL_PERIOD = 500\n",
    "\n",
    "# ðŸ“‚ Direktori output\n",
    "cfg.OUTPUT_DIR = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_5e-5_Adam\"\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xg7Zu6JLtEZo"
   },
   "source": [
    "# **Training Skenario 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4065667,
     "status": "ok",
     "timestamp": 1749915464638,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "l26z2HK3VgdJ",
    "outputId": "eecba4f6-4ed1-4178-e253-80d654d461e9"
   },
   "outputs": [],
   "source": [
    "from detectron2.engine.hooks import BestCheckpointer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.utils.events import EventStorage\n",
    "\n",
    "import torch\n",
    "\n",
    "# ðŸ§  Custom Trainer class\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "\n",
    "    @classmethod\n",
    "    def build_optimizer(cls, cfg, model):\n",
    "        \"\"\"\n",
    "        Override default SGD optimizer with Adam\n",
    "        \"\"\"\n",
    "        params = []\n",
    "        for name, param in model.named_parameters():\n",
    "            if not param.requires_grad:\n",
    "                continue\n",
    "            lr = cfg.SOLVER.BASE_LR\n",
    "            if \"bias\" in name:\n",
    "                weight_decay = cfg.SOLVER.WEIGHT_DECAY_BIAS\n",
    "            elif \"norm\" in name:\n",
    "                weight_decay = cfg.SOLVER.WEIGHT_DECAY_NORM  # Tambahkan decay norm\n",
    "            else:\n",
    "                weight_decay = cfg.SOLVER.WEIGHT_DECAY\n",
    "            params.append({\"params\": [param], \"lr\": lr, \"weight_decay\": weight_decay})\n",
    "\n",
    "        optimizer = torch.optim.Adam(params, lr=cfg.SOLVER.BASE_LR)\n",
    "        return optimizer\n",
    "\n",
    "    def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        hooks.insert(\n",
    "            -1,\n",
    "            BestCheckpointer(\n",
    "                cfg.TEST.EVAL_PERIOD,\n",
    "                checkpointer=DetectionCheckpointer(self.model, cfg.OUTPUT_DIR),\n",
    "                val_metric=\"bbox/AP\",\n",
    "                mode=\"max\",\n",
    "                file_prefix=\"best_model\"\n",
    "            )\n",
    "        )\n",
    "        return hooks\n",
    "\n",
    "# Inisialisasi trainer dan mulai training\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHbLbQuuuB-_"
   },
   "source": [
    "# **Simpan Konfigurasi Model RetinaNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBfYbKgsfGby"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(cfg.OUTPUT_DIR, \"config.yaml\"), \"w\") as f:\n",
    "    f.write(cfg.dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZxsK43qualR"
   },
   "source": [
    "# **Prediksi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 890
    },
    "executionInfo": {
     "elapsed": 2078,
     "status": "ok",
     "timestamp": 1749915545033,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "2_uIZ3fCfKKH",
    "outputId": "1b366a7b-9cee-46f3-e131-3bccc941204a"
   },
   "outputs": [],
   "source": [
    "# ðŸ§  Load the trained model\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"best_model.pth\")  # Load the weights from your training\n",
    "#cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Set threshold to 50% for detection\n",
    "\n",
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# ðŸ“¸ Read the image\n",
    "#image_path = '/content/valid/00000732_005_jpg.rf.3541c4c659fec2d5d003b4fb7a380dea.jpg'\n",
    "image_path = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Dataset/test/9ed1f91369552618456da255b02820b3_jpg.rf.17cd671024249e0b1f3a9e36be41a928.jpg\"\n",
    "im = cv2.imread(image_path)\n",
    "\n",
    "# ðŸ§  Run inference\n",
    "outputs = predictor(im)\n",
    "\n",
    "# Filter instances with confidence\n",
    "confidence = 0.5\n",
    "instances = outputs[\"instances\"]\n",
    "scores = instances.scores\n",
    "filtered_instances = instances[scores > confidence]\n",
    "\n",
    "# ðŸ–¼ï¸ Visualize the results\n",
    "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(\"roboflow_train\"), scale=1)\n",
    "v = v.draw_instance_predictions(filtered_instances.to(\"cpu\"))\n",
    "\n",
    "# Show the image with filtered instances\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(v.get_image())\n",
    "plt.show()\n",
    "\n",
    "# Optionally, print out the number of detections\n",
    "print(f\"Detected {len(filtered_instances)} objects with confidence > {confidence*100}%.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NOdILvcvl4c"
   },
   "source": [
    "# **Grafik Evaluasi Record Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 4437,
     "status": "ok",
     "timestamp": 1749992241103,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "opzQqI39ffaC",
    "outputId": "7712bcf8-770d-467e-bfe6-1f2d4bf29e6d"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tentukan path ke file metrics.json\n",
    "metrics_file = '/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_1e-5_Adam/metrics.json'  # Ganti dengan path file Anda\n",
    "\n",
    "# Menyaring data untuk total_loss\n",
    "iterations = []\n",
    "total_loss = []\n",
    "\n",
    "# Membaca file JSON baris per baris\n",
    "with open(metrics_file, 'r') as f:\n",
    "    for line in f:\n",
    "        # Memuat setiap baris JSON\n",
    "        entry = json.loads(line)\n",
    "\n",
    "        # Menyaring data untuk iteration dan total_loss\n",
    "        if 'iteration' in entry and 'total_loss' in entry:\n",
    "            iterations.append(entry['iteration'])\n",
    "            total_loss.append(entry['total_loss'])\n",
    "\n",
    "# Membuat grafik untuk total loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(iterations, total_loss, label=\"Total Loss\", color='tab:blue')\n",
    "\n",
    "# Menambahkan judul dan label sumbu\n",
    "plt.title('Total Loss over Iterations')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Total Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "# Menampilkan grafik\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "executionInfo": {
     "elapsed": 856,
     "status": "ok",
     "timestamp": 1749992249418,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "hDmq1Y3-fmt7",
    "outputId": "1f058ff5-53f4-4663-c4ba-21c23958ca4a"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Path ke file metrics.json\n",
    "metrics_file = '/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_1e-5_Adam/metrics.json'  # Ganti sesuai path Anda\n",
    "\n",
    "# Inisialisasi list untuk menyimpan data\n",
    "iterations = []\n",
    "total_loss = []\n",
    "loss_cls = []\n",
    "loss_bbox = []\n",
    "\n",
    "# Membaca dan memproses file JSON baris per baris\n",
    "with open(metrics_file, 'r') as f:\n",
    "    for line in f:\n",
    "        entry = json.loads(line)\n",
    "\n",
    "        if 'iteration' in entry:\n",
    "            iterations.append(entry['iteration'])\n",
    "            total_loss.append(entry.get('total_loss', None))\n",
    "            loss_cls.append(entry.get('loss_cls', None))\n",
    "            loss_bbox.append(entry.get('loss_box_reg', None))\n",
    "\n",
    "# Membuat grafik\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "plt.plot(iterations, total_loss, label='Total Loss', color='tab:blue')\n",
    "plt.plot(iterations, loss_cls, label='Classification Loss (loss_cls)', color='tab:orange')\n",
    "plt.plot(iterations, loss_bbox, label='BBox Loss (loss_bbox)', color='tab:green')\n",
    "\n",
    "# Menambahkan elemen visual\n",
    "plt.title('Loss over Iterations')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Menampilkan grafik\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "executionInfo": {
     "elapsed": 5628,
     "status": "ok",
     "timestamp": 1749992334219,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "BR7axaLMgOiX",
    "outputId": "a2dfee39-ff7e-421b-eb0c-771813369a37"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tentukan path ke file metrics.json\n",
    "metrics_file = '/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_1e-5_Adam/metrics.json'  # Ganti dengan path file Anda\n",
    "\n",
    "# Menyaring data untuk AP\n",
    "iterations = []\n",
    "bbox_ap = []\n",
    "bbox_ap50 = []\n",
    "bbox_ap75 = []\n",
    "bbox_ap_cardio = []\n",
    "bbox_ap_nodule = []\n",
    "bbox_ap_pneumo = []\n",
    "\n",
    "# Membaca file JSON baris per baris\n",
    "with open(metrics_file, 'r') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            entry = json.loads(line)\n",
    "\n",
    "            # Pastikan hanya memasukkan data yang mengandung metrik 'bbox/AP'\n",
    "            if 'bbox/AP' in entry:\n",
    "                iterations.append(entry['iteration'])\n",
    "                bbox_ap.append(entry['bbox/AP'])\n",
    "                bbox_ap50.append(entry.get('bbox/AP50', None))\n",
    "                bbox_ap75.append(entry.get('bbox/AP75', None))\n",
    "                bbox_ap_cardio.append(entry.get('bbox/AP-Cardiomegaly', None))\n",
    "                bbox_ap_nodule.append(entry.get('bbox/AP-Nodule-Mass', None))\n",
    "                bbox_ap_pneumo.append(entry.get('bbox/AP-Pneumothorax', None))\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing line: {e}\")\n",
    "            continue\n",
    "\n",
    "# Memastikan ada data untuk plotting\n",
    "print(f\"Total data points: {len(iterations)}\")\n",
    "\n",
    "# Jika ada data untuk plotting, buat grafik\n",
    "if iterations:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plotting berbagai metrik AP\n",
    "    plt.plot(iterations, bbox_ap, label=\"bbox/AP\", color='tab:blue')\n",
    "    plt.plot(iterations, bbox_ap50, label=\"bbox/AP50\", color='tab:orange')\n",
    "    plt.plot(iterations, bbox_ap75, label=\"bbox/AP75\", color='tab:green')\n",
    "    plt.plot(iterations, bbox_ap_cardio, label=\"bbox/AP-Cardiomegaly\", color='tab:red')\n",
    "    plt.plot(iterations, bbox_ap_nodule, label=\"bbox/AP-Nodule-Mass\", color='tab:purple')\n",
    "    plt.plot(iterations, bbox_ap_pneumo, label=\"bbox/AP-Pneumothorax\", color='tab:brown')\n",
    "\n",
    "    # Menambahkan judul dan label sumbu\n",
    "    plt.title('Average Precision (AP) over Iterations')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Average Precision (AP)')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Menampilkan legenda\n",
    "    plt.legend()\n",
    "\n",
    "    # Menampilkan grafik\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Tidak ada data untuk plot.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1749992349138,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "peVbMtGEgUoY",
    "outputId": "42145edd-637f-4e40-c282-422775aed845"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Menentukan path file metrics.json di Google Drive\n",
    "file_path = '/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_1e-5_Adam/metrics.json'\n",
    "\n",
    "# Memuat file metrics.json\n",
    "with open(file_path, 'r') as file:\n",
    "    data = [json.loads(line) for line in file.readlines()]\n",
    "\n",
    "# Menyaring nilai AP per kelas dari data terakhir\n",
    "metrics = data[-1]  # Mengambil data terakhir yang berisi AP\n",
    "\n",
    "# Mengambil nilai AP per kelas\n",
    "ap_values = {\n",
    "    \"Cardiomegaly\": metrics.get('bbox/AP-Cardiomegaly', 0),\n",
    "    \"Nodule-Mass\": metrics.get('bbox/AP-Nodule-Mass', 0),\n",
    "    \"Pneumothorax\": metrics.get('bbox/AP-Pneumothorax', 0),\n",
    "}\n",
    "\n",
    "# Menghitung mAP (mean Average Precision)\n",
    "ap_values_list = list(ap_values.values())\n",
    "map_score = sum(ap_values_list) / len(ap_values_list)\n",
    "\n",
    "# Menampilkan hasil\n",
    "print(\"AP per kelas:\")\n",
    "for class_name, ap in ap_values.items():\n",
    "    print(f\"{class_name}: {ap:.4f}\")\n",
    "\n",
    "print(f\"\\nmAP: {map_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 191,
     "status": "ok",
     "timestamp": 1749992371555,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "u1MeTaPwgawr",
    "outputId": "0e3de895-934b-4798-da3d-24efdbc40b82"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Menentukan path file metrics.json (update dengan path yang sesuai)\n",
    "file_path = '/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_1e-5_Adam/metrics.json'\n",
    "\n",
    "# Memuat file metrics.json\n",
    "with open(file_path, 'r') as file:\n",
    "    data = [json.loads(line) for line in file.readlines()]\n",
    "\n",
    "# Menyaring nilai AP per kelas dari data terakhir\n",
    "ap_per_iteration = []\n",
    "map_per_iteration = []\n",
    "\n",
    "# Menyaring nilai AP per kelas dan mAP dari setiap iterasi\n",
    "for metrics in data:\n",
    "    # Mengecek apakah nilai AP ada dalam data\n",
    "    if 'bbox/AP-Cardiomegaly' in metrics and 'bbox/AP-Nodule-Mass' in metrics and 'bbox/AP-Pneumothorax' in metrics:\n",
    "        ap_values = {\n",
    "            \"Cardiomegaly\": metrics.get('bbox/AP-Cardiomegaly', 0),\n",
    "            \"Nodule-Mass\": metrics.get('bbox/AP-Nodule-Mass', 0),\n",
    "            \"Pneumothorax\": metrics.get('bbox/AP-Pneumothorax', 0),\n",
    "        }\n",
    "\n",
    "        # Menghitung mAP (mean Average Precision)\n",
    "        ap_values_list = list(ap_values.values())\n",
    "        map_score = sum(ap_values_list) / len(ap_values_list)\n",
    "\n",
    "        ap_per_iteration.append(ap_values)\n",
    "        map_per_iteration.append(map_score)\n",
    "\n",
    "# Menyiapkan data untuk grafik\n",
    "iterations = range(1, len(map_per_iteration) + 1)\n",
    "\n",
    "# Plotting mAP per iterasi\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(iterations, map_per_iteration, label='mAP (mean Average Precision)', color='blue', linewidth=2)\n",
    "\n",
    "# Menambahkan grafik untuk setiap kelas\n",
    "for class_name in ap_per_iteration[0].keys():\n",
    "    class_ap_values = [ap[class_name] for ap in ap_per_iteration]\n",
    "    plt.plot(iterations, class_ap_values, label=f'AP-{class_name}', linestyle='--')\n",
    "\n",
    "# Menambahkan label dan judul\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Average Precision')\n",
    "plt.title('mAP and AP per Class over Iterations')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Menampilkan grafik\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 640,
     "status": "ok",
     "timestamp": 1749992403291,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "omJo0_rqgo9c",
    "outputId": "908caef6-0453-488d-9524-009675bdab7a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Path file di Google Drive (sesuaikan dengan path file Anda)\n",
    "file_path = '/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_1e-5_Adam/metrics.json'\n",
    "\n",
    "# Memuat data dari file metrics.json\n",
    "with open(file_path, 'r') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# Menyiapkan data untuk plot\n",
    "iterations = []\n",
    "loss_cls_values = []\n",
    "loss_box_reg_values = []\n",
    "\n",
    "# Looping untuk mengekstrak data\n",
    "for metrics in data:\n",
    "    # Pastikan ada key yang dibutuhkan\n",
    "    if 'iteration' in metrics:\n",
    "        iterations.append(metrics['iteration'])\n",
    "    if 'loss_cls' in metrics:\n",
    "        loss_cls_values.append(metrics['loss_cls'])\n",
    "    if 'loss_box_reg' in metrics:\n",
    "        loss_box_reg_values.append(metrics['loss_box_reg'])\n",
    "\n",
    "# Pastikan panjang data sama, dan jika tidak, sesuaikan panjangnya\n",
    "min_len = min(len(iterations), len(loss_cls_values), len(loss_box_reg_values))\n",
    "\n",
    "# Potong data agar memiliki panjang yang sama\n",
    "iterations = iterations[:min_len]\n",
    "loss_cls_values = loss_cls_values[:min_len]\n",
    "loss_box_reg_values = loss_box_reg_values[:min_len]\n",
    "\n",
    "# Membuat plot jika data ada\n",
    "if iterations and loss_cls_values and loss_box_reg_values:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot Loss Klasifikasi\n",
    "    plt.plot(iterations, loss_cls_values, label='Loss Klasifikasi', color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "    # Plot Loss Regresi Batas\n",
    "    plt.plot(iterations, loss_box_reg_values, label='Loss Regresi Bounding Box', color='green', linestyle='-', linewidth=2)\n",
    "\n",
    "    # Menambahkan label dan judul\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Klasifikasi dan Loss Regresi Bounding Box')\n",
    "\n",
    "    # Menambahkan legend\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    # Menampilkan grid\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Menampilkan grafik\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Data tidak lengkap, pastikan key 'loss_cls' dan 'loss_box_reg' ada dalam setiap entri.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1996,
     "status": "ok",
     "timestamp": 1749992451911,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "oXwaPupwvapM",
    "outputId": "9379c37f-ddec-4d6a-c2d1-22257450991d"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Path file metrics.json\n",
    "file_path = '/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_1e-5_Adam/metrics.json'\n",
    "\n",
    "# Load file JSON\n",
    "with open(file_path, 'r') as file:\n",
    "    data = [json.loads(line) for line in file.readlines()]\n",
    "\n",
    "# Menyimpan AP per kelas dan iterasi\n",
    "ap_per_iteration = { \"Cardiomegaly\": [], \"Nodule-Mass\": [], \"Pneumothorax\": [] }\n",
    "iteration_list = []\n",
    "\n",
    "# Ekstraksi AP dan iterasi\n",
    "for metrics in data:\n",
    "    if all(k in metrics for k in ['bbox/AP-Cardiomegaly', 'bbox/AP-Nodule-Mass', 'bbox/AP-Pneumothorax']):\n",
    "        iteration = metrics.get(\"iteration\", None)\n",
    "        if iteration is not None:\n",
    "            iteration_list.append(iteration)\n",
    "            ap_per_iteration[\"Cardiomegaly\"].append(metrics['bbox/AP-Cardiomegaly'])\n",
    "            ap_per_iteration[\"Nodule-Mass\"].append(metrics['bbox/AP-Nodule-Mass'])\n",
    "            ap_per_iteration[\"Pneumothorax\"].append(metrics['bbox/AP-Pneumothorax'])\n",
    "\n",
    "# Plot untuk setiap kelas\n",
    "for class_name, ap_values in ap_per_iteration.items():\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(iteration_list, ap_values, marker='o', color='red', label=f'bbox/AP-{class_name}')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Average Precision (AP)')\n",
    "    plt.title(f'Average Precision (AP) {class_name} over Iterations')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nV44Sg9jv5H8"
   },
   "source": [
    "# **Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Om3cwA0lgvdR"
   },
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    box: [xmin, ymin, xmax, ymax]\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x1g, y1g, x2g, y2g = box2\n",
    "\n",
    "    xi1 = max(x1, x1g)\n",
    "    yi1 = max(y1, y1g)\n",
    "    xi2 = min(x2, x2g)\n",
    "    yi2 = min(y2, y2g)\n",
    "    inter_area = max(xi2 - xi1, 0) * max(yi2 - yi1, 0)\n",
    "\n",
    "    box1_area = (x2 - x1) * (y2 - y1)\n",
    "    box2_area = (x2g - x1g) * (y2g - y1g)\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "    if union_area == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return inter_area / union_area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "executionInfo": {
     "elapsed": 13164,
     "status": "ok",
     "timestamp": 1749915718923,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "e6ubu2S2gyQt",
    "outputId": "e75e4f79-a2ce-4725-9c55-f4696a336d59"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# ðŸ§  Load model\n",
    "# cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"best_model.pth\")\n",
    "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_5e-5_Adam/best_model.pth\"\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# ðŸ“š Prepare dataset paths\n",
    "test_image_dir = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Dataset/dataset_new/test\"\n",
    "coco_annotation_path = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Dataset/dataset_new/test/_annotations.coco.json\"\n",
    "\n",
    "# Load COCO ground truth\n",
    "with open(coco_annotation_path) as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# Build image_id to filename mapping\n",
    "id_to_filename = {img['id']: img['file_name'] for img in coco_data['images']}\n",
    "\n",
    "# Build annotations mapping\n",
    "annotations = coco_data['annotations']\n",
    "gt_dict = {}  # {filename: (boxes, labels)}\n",
    "\n",
    "for ann in annotations:\n",
    "    image_id = ann['image_id']\n",
    "    filename = id_to_filename[image_id]\n",
    "    bbox = ann['bbox']  # [x, y, width, height]\n",
    "    category_id = ann['category_id']\n",
    "\n",
    "    if filename not in gt_dict:\n",
    "        gt_dict[filename] = {'boxes': [], 'labels': []}\n",
    "\n",
    "    # Convert bbox format to [xmin, ymin, xmax, ymax]\n",
    "    xmin, ymin, w, h = bbox\n",
    "    xmax = xmin + w\n",
    "    ymax = ymin + h\n",
    "\n",
    "    gt_dict[filename]['boxes'].append([xmin, ymin, xmax, ymax])\n",
    "    gt_dict[filename]['labels'].append(category_id)\n",
    "\n",
    "# Build category_id to class_name mapping\n",
    "category_id_to_name = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
    "class_names = [category_id_to_name[i] for i in sorted(category_id_to_name.keys())]\n",
    "\n",
    "# ðŸ”¥ Start evaluating\n",
    "y_true = []\n",
    "y_pred = []\n",
    "iou_threshold = 0.5\n",
    "confidence_threshold = 0.5\n",
    "\n",
    "test_images = sorted(os.listdir(test_image_dir))\n",
    "test_images = [img for img in test_images if img.endswith('.jpg') or img.endswith('.png')]\n",
    "\n",
    "for img_file in tqdm(test_images, desc=\"Processing Test Images\"):\n",
    "    # Read image\n",
    "    img_path = os.path.join(test_image_dir, img_file)\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    if img_file not in gt_dict:\n",
    "        continue  # skip images without ground truth\n",
    "\n",
    "    gt_boxes = np.array(gt_dict[img_file]['boxes'])\n",
    "    gt_classes = np.array(gt_dict[img_file]['labels'])\n",
    "\n",
    "    # Predict\n",
    "    outputs = predictor(img)\n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "\n",
    "    pred_boxes = instances.pred_boxes.tensor.numpy()\n",
    "    pred_classes = instances.pred_classes.numpy()\n",
    "    pred_scores = instances.scores.numpy()\n",
    "\n",
    "    # Filter predictions by confidence\n",
    "    keep = pred_scores > confidence_threshold\n",
    "    pred_boxes = pred_boxes[keep]\n",
    "    pred_classes = pred_classes[keep]\n",
    "\n",
    "    matched_gt = set()\n",
    "\n",
    "    # Matching predicted boxes to ground truth boxes\n",
    "    for pred_box, pred_class in zip(pred_boxes, pred_classes):\n",
    "        best_iou = 0\n",
    "        best_idx = -1\n",
    "        for idx, gt_box in enumerate(gt_boxes):\n",
    "            iou = calculate_iou(pred_box, gt_box)\n",
    "            if iou > best_iou and idx not in matched_gt:\n",
    "                best_iou = iou\n",
    "                best_idx = idx\n",
    "        if best_iou >= iou_threshold and best_idx != -1:\n",
    "            y_true.append(gt_classes[best_idx])\n",
    "            y_pred.append(pred_class)\n",
    "            matched_gt.add(best_idx)\n",
    "        else:\n",
    "            # False positive\n",
    "            y_true.append(-1)  # background\n",
    "            y_pred.append(pred_class)\n",
    "\n",
    "    # False negatives\n",
    "    for idx, gt_class in enumerate(gt_classes):\n",
    "        if idx not in matched_gt:\n",
    "            y_true.append(gt_class)\n",
    "            y_pred.append(-1)\n",
    "\n",
    "# ðŸ”¥ Build Confusion Matrix\n",
    "all_labels = sorted(list(set([lab for lab in y_true if lab != -1] + [lab for lab in y_pred if lab != -1])))\n",
    "cm = confusion_matrix(y_true, y_pred, labels=all_labels)\n",
    "\n",
    "class_labels = [category_id_to_name[i] for i in all_labels]\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix - RetinaNet Detectron2 (COCO Format)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ymu7D9mZRILp"
   },
   "source": [
    "# **Evaluasi Data Train, Validasi, dan Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3691638,
     "status": "ok",
     "timestamp": 1749919431174,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "QZOAVYVYRKmS",
    "outputId": "333ca07c-748d-4cb9-bee2-ff0c7cf89834"
   },
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.modeling import build_model\n",
    "\n",
    "# Load config dan model\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_5e-5_Adam/config.yaml\")\n",
    "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_5e-5_Adam/best_model.pth\"\n",
    "cfg.MODEL.DEVICE = 'cpu'  # atau 'cpu'\n",
    "cfg.DATASETS.TEST = (\"roboflow_train\",)\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.5\n",
    "\n",
    "evaluator = COCOEvaluator(\"roboflow_train\", cfg, False, output_dir=\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_5e-5_Adam/eval_train\")\n",
    "val_loader = build_detection_test_loader(cfg, \"roboflow_train\")\n",
    "\n",
    "model = build_model(cfg)\n",
    "DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)\n",
    "\n",
    "results = inference_on_dataset(model, val_loader, evaluator)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 456277,
     "status": "ok",
     "timestamp": 1749919920009,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "-NFxHs_juofG",
    "outputId": "90363509-a40b-446a-8ffb-ebdc11dfcc28"
   },
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.modeling import build_model\n",
    "\n",
    "# Load config dan model\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_5e-5_Adam/config.yaml\")\n",
    "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_5e-5_Adam/best_model.pth\"\n",
    "cfg.MODEL.DEVICE = 'cpu'  # atau 'cpu'\n",
    "cfg.DATASETS.TEST = (\"roboflow_val\",)\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.5\n",
    "\n",
    "evaluator = COCOEvaluator(\"roboflow_val\", cfg, False, output_dir=\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_5e-5_Adam/eval_valid\")\n",
    "val_loader = build_detection_test_loader(cfg, \"roboflow_val\")\n",
    "\n",
    "model = build_model(cfg)\n",
    "DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)\n",
    "\n",
    "results = inference_on_dataset(model, val_loader, evaluator)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 451617,
     "status": "ok",
     "timestamp": 1749920391472,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "eZoT0AX9u2Fo",
    "outputId": "8af99b39-28c5-4664-b08b-b8c9c99e0f2a"
   },
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.modeling import build_model\n",
    "\n",
    "# Load config dan model\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_5e-5_Adam/config.yaml\")\n",
    "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_5e-5_Adam/best_model.pth\"\n",
    "cfg.MODEL.DEVICE = 'cpu'  # atau 'cpu'\n",
    "cfg.DATASETS.TEST = (\"roboflow_test\",)\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.5\n",
    "\n",
    "evaluator = COCOEvaluator(\"roboflow_test\", cfg, False, output_dir=\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_30_5e-5_Adam/eval_test\")\n",
    "val_loader = build_detection_test_loader(cfg, \"roboflow_test\")\n",
    "\n",
    "model = build_model(cfg)\n",
    "DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)\n",
    "\n",
    "results = inference_on_dataset(model, val_loader, evaluator)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3cFM0NdvNoO2"
   },
   "outputs": [],
   "source": [
    "from detectron2.evaluation.evaluator import DatasetEvaluator\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class PRF1Evaluator(DatasetEvaluator):\n",
    "    def __init__(self, dataset_name, metadata, class_names=None):\n",
    "        from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "        self.metadata = MetadataCatalog.get(dataset_name)\n",
    "        self.dataset_dicts = DatasetCatalog.get(dataset_name)\n",
    "        self.class_names = class_names if class_names else self.metadata.thing_classes\n",
    "        self.gts = []\n",
    "        self.preds = []\n",
    "\n",
    "        # Buat mapping image_id ke daftar ground truth class ID\n",
    "        self.imgid_to_gt = {}\n",
    "        for data in self.dataset_dicts:\n",
    "            gt_classes = [ann[\"category_id\"] for ann in data[\"annotations\"]]\n",
    "            self.imgid_to_gt[data[\"image_id\"]] = gt_classes\n",
    "\n",
    "    def reset(self):\n",
    "        self.gts = []\n",
    "        self.preds = []\n",
    "\n",
    "    def process(self, inputs, outputs):\n",
    "        for input, output in zip(inputs, outputs):\n",
    "            img_id = input[\"image_id\"]\n",
    "            gt_classes = self.imgid_to_gt.get(img_id, [])\n",
    "            pred_classes = output[\"instances\"].pred_classes.cpu().numpy() if len(output[\"instances\"]) > 0 else []\n",
    "\n",
    "            # Samakan panjang prediksi dan ground truth\n",
    "            if len(pred_classes) < len(gt_classes):\n",
    "                pred_classes = list(pred_classes) + [-1] * (len(gt_classes) - len(pred_classes))\n",
    "            elif len(pred_classes) > len(gt_classes):\n",
    "                pred_classes = pred_classes[:len(gt_classes)]\n",
    "\n",
    "            self.gts.extend(gt_classes)\n",
    "            self.preds.extend(pred_classes)\n",
    "\n",
    "    def evaluate(self):\n",
    "        print(\"\\n==== Precision, Recall, and F1-Score per Class ====\\n\")\n",
    "\n",
    "        # Ambil hasil sebagai dictionary\n",
    "        report_dict = classification_report(\n",
    "            self.gts,\n",
    "            self.preds,\n",
    "            target_names=self.class_names,\n",
    "            output_dict=True,\n",
    "            digits=3,\n",
    "            zero_division=0\n",
    "        )\n",
    "\n",
    "        # Konversi ke DataFrame\n",
    "        df = pd.DataFrame(report_dict).transpose()\n",
    "        df.index.name = 'Class'\n",
    "\n",
    "        # Ambil dan simpan nilai akurasi, hapus dari tabel supaya tampil rapi\n",
    "        accuracy = report_dict.get(\"accuracy\", None)\n",
    "        if \"accuracy\" in df.index:\n",
    "            df.drop(\"accuracy\", inplace=True)\n",
    "\n",
    "        # Ubah support menjadi integer\n",
    "        if 'support' in df.columns:\n",
    "            df['support'] = df['support'].astype(int)\n",
    "\n",
    "        # Urutkan kolom\n",
    "        df = df[['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "        # Cetak tabel\n",
    "        print(df.to_string(float_format=\"%.3f\"))\n",
    "\n",
    "        # Cetak akurasi secara terpisah\n",
    "        if accuracy is not None:\n",
    "            print(f\"\\nOverall Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "        # Return hanya data, tanpa tampilkan dict sebagai output Python\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73582,
     "status": "ok",
     "timestamp": 1749920501778,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "lROmuuLbNqyd",
    "outputId": "97d15eb5-a3a2-4d01-c77e-3df0b2c9236d"
   },
   "outputs": [],
   "source": [
    "class_names = [\"Cardiomegaly\", \"Nodule/Mass\", \"Pneumothorax\"]\n",
    "\n",
    "evaluator_test = PRF1Evaluator(\"roboflow_train\", cfg, class_names=class_names)\n",
    "test_loader = build_detection_test_loader(cfg, \"roboflow_train\")\n",
    "inference_on_dataset(trainer.model, test_loader, evaluator_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9269,
     "status": "ok",
     "timestamp": 1749920542717,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "IT-ehmLSNtfs",
    "outputId": "f9955a8c-eae4-4317-f02a-66a5c119f924"
   },
   "outputs": [],
   "source": [
    "class_names = [\"Cardiomegaly\", \"Nodule/Mass\", \"Pneumothorax\"]\n",
    "\n",
    "evaluator_test = PRF1Evaluator(\"roboflow_val\", cfg, class_names=class_names)\n",
    "test_loader = build_detection_test_loader(cfg, \"roboflow_val\")\n",
    "inference_on_dataset(trainer.model, test_loader, evaluator_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9185,
     "status": "ok",
     "timestamp": 1749920593940,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "XYFVPROVNvxs",
    "outputId": "0c2e7b48-44d4-479b-80e9-31d4dd776b85"
   },
   "outputs": [],
   "source": [
    "class_names = [\"Cardiomegaly\", \"Nodule/Mass\", \"Pneumothorax\"]\n",
    "\n",
    "evaluator_test = PRF1Evaluator(\"roboflow_test\", cfg, class_names=class_names)\n",
    "test_loader = build_detection_test_loader(cfg, \"roboflow_test\")\n",
    "inference_on_dataset(trainer.model, test_loader, evaluator_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOfJ3L31q+eCJuK+PkcscCq",
   "collapsed_sections": [
    "ExP8iZJWNIKz",
    "wakic4yzUge_",
    "Xg7Zu6JLtEZo",
    "cHbLbQuuuB-_",
    "NZxsK43qualR"
   ],
   "gpuType": "T4",
   "mount_file_id": "1vwgnOoRzBrQiAHzcv3jCIs4_jdlhfqYi",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
