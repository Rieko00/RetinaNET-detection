{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STHkhYgVxxFy"
   },
   "source": [
    "# **Install Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 254471,
     "status": "ok",
     "timestamp": 1751980723039,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "Au7sa_HS_vTz",
    "outputId": "441e064a-ba24-4aa7-d8e6-570f0bd626d6"
   },
   "outputs": [],
   "source": [
    "# ðŸ“¦ Install dependencies\n",
    "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
    "!pip install -q pycocotools\n",
    "\n",
    "# ðŸ”§ Setup: Import\n",
    "import os\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "import random\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJHtcztlx3-A"
   },
   "source": [
    "# **Register Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1751980870852,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "MCVWG_FuAMB8",
    "outputId": "2b8c08fa-47fe-465f-b677-81f9d0e4365a"
   },
   "outputs": [],
   "source": [
    "# Set root folder di Google Drive\n",
    "dataset_root = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Dataset/dataset_new\"\n",
    "\n",
    "# Buat path lengkap ke JSON dan folder gambar\n",
    "train_json = os.path.join(dataset_root, \"train/_annotations.coco.json\")\n",
    "val_json = os.path.join(dataset_root, \"valid/_annotations.coco.json\")\n",
    "test_json = os.path.join(dataset_root, \"test/_annotations.coco.json\")\n",
    "train_img_dir = os.path.join(dataset_root, \"train\")\n",
    "val_img_dir = os.path.join(dataset_root, \"valid\")\n",
    "test_img_dir = os.path.join(dataset_root, \"test\")\n",
    "\n",
    "# âœ… Cek apakah file dan folder ada\n",
    "print(\"Train JSON exists:\", os.path.exists(train_json))\n",
    "print(\"Train Image Dir exists:\", os.path.exists(train_img_dir))\n",
    "\n",
    "# ðŸ—‚ Daftarkan dataset ke Detectron2\n",
    "register_coco_instances(\"roboflow_train\", {}, train_json, train_img_dir)\n",
    "register_coco_instances(\"roboflow_val\", {}, val_json, val_img_dir)\n",
    "register_coco_instances(\"roboflow_test_1\", {}, test_json, test_img_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EF1MjNqx7aS"
   },
   "source": [
    "# **Konfigurasi Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 441,
     "status": "ok",
     "timestamp": 1749898206888,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "ass9T4p9AQjz",
    "outputId": "fec9cb1c-9112-4700-bd2b-36279ed9de80"
   },
   "outputs": [],
   "source": [
    "from detectron2 import model_zoo\n",
    "\n",
    "# ðŸ§  Configure RetinaNet\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"roboflow_train\",)\n",
    "cfg.DATASETS.TEST = (\"roboflow_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.MODEL.WEIGHTS = \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
    "cfg.SOLVER.IMS_PER_BATCH = 16\n",
    "cfg.SOLVER.BASE_LR = 0.0001\n",
    "cfg.SOLVER.MAX_ITER = 2800\n",
    "cfg.TEST.EVAL_PERIOD = 500  # Evaluate every 500 iterations\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.MODEL.RETINANET.NUM_CLASSES = 4  # âš ï¸ Update this if more than 1 class\n",
    "# â¬…ï¸ Tambahkan ini untuk mendukung Adam optimizer\n",
    "cfg.SOLVER.WEIGHT_DECAY = 0.0001\n",
    "cfg.SOLVER.WEIGHT_DECAY_BIAS = 0.0\n",
    "cfg.OUTPUT_DIR = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_Adam\"\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VsJhGZXzx_0I"
   },
   "source": [
    "# **Training Skenario 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6187415,
     "status": "ok",
     "timestamp": 1749904402762,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "qwSQa2f7BHrW",
    "outputId": "b99cb74b-ded9-4b2a-ce76-106494781323"
   },
   "outputs": [],
   "source": [
    "from detectron2.engine.hooks import BestCheckpointer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.utils.events import EventStorage\n",
    "\n",
    "import torch\n",
    "\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "\n",
    "    @classmethod\n",
    "    def build_optimizer(cls, cfg, model):\n",
    "        \"\"\"\n",
    "        Override default SGD optimizer with Adam\n",
    "        \"\"\"\n",
    "        params = []\n",
    "        for key, value in model.named_parameters():\n",
    "            if not value.requires_grad:\n",
    "                continue\n",
    "            lr = cfg.SOLVER.BASE_LR\n",
    "            weight_decay = cfg.SOLVER.WEIGHT_DECAY\n",
    "            # Bias parameter biasanya dikurangi decay-nya\n",
    "            if \"bias\" in key:\n",
    "                weight_decay = cfg.SOLVER.WEIGHT_DECAY_BIAS\n",
    "            params += [{\"params\": [value], \"lr\": lr, \"weight_decay\": weight_decay}]\n",
    "\n",
    "        optimizer = torch.optim.Adam(params, lr=cfg.SOLVER.BASE_LR)\n",
    "        return optimizer\n",
    "\n",
    "    def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        # Save the best checkpoint based on bbox/AP\n",
    "        hooks.insert(\n",
    "            -1,\n",
    "            BestCheckpointer(\n",
    "                cfg.TEST.EVAL_PERIOD,\n",
    "                checkpointer=DetectionCheckpointer(self.model, cfg.OUTPUT_DIR),\n",
    "                val_metric=\"bbox/AP\",\n",
    "                mode=\"max\",\n",
    "                file_prefix=\"best_model\"\n",
    "            )\n",
    "        )\n",
    "        return hooks\n",
    "\n",
    "# Inisialisasi trainer dan mulai training\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6N6QKdaTyEiB"
   },
   "source": [
    "# **Simpan Konfigurasi Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZ9rlT1_PTmY"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(cfg.OUTPUT_DIR, \"config.yaml\"), \"w\") as f:\n",
    "    f.write(cfg.dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-ACZfiLyMJg"
   },
   "source": [
    "# **Prediksi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 890
    },
    "executionInfo": {
     "elapsed": 2742,
     "status": "ok",
     "timestamp": 1749904430164,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "jNhgrKoLP2QL",
    "outputId": "e21190dc-5486-4be6-eac5-fa6121ef1576"
   },
   "outputs": [],
   "source": [
    "# ðŸ§  Load the trained model\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"best_model.pth\")  # Load the weights from your training\n",
    "#cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Set threshold to 50% for detection\n",
    "\n",
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# ðŸ“¸ Read the image\n",
    "#image_path = '/content/valid/00000732_005_jpg.rf.3541c4c659fec2d5d003b4fb7a380dea.jpg'\n",
    "image_path = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Dataset/test/9ed1f91369552618456da255b02820b3_jpg.rf.17cd671024249e0b1f3a9e36be41a928.jpg\"\n",
    "im = cv2.imread(image_path)\n",
    "\n",
    "# ðŸ§  Run inference\n",
    "outputs = predictor(im)\n",
    "\n",
    "# Filter instances with confidence\n",
    "confidence = 0.5\n",
    "instances = outputs[\"instances\"]\n",
    "scores = instances.scores\n",
    "filtered_instances = instances[scores > confidence]\n",
    "\n",
    "# ðŸ–¼ï¸ Visualize the results\n",
    "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(\"roboflow_train\"), scale=1)\n",
    "v = v.draw_instance_predictions(filtered_instances.to(\"cpu\"))\n",
    "\n",
    "# Show the image with filtered instances\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(v.get_image())\n",
    "plt.show()\n",
    "\n",
    "# Optionally, print out the number of detections\n",
    "print(f\"Detected {len(filtered_instances)} objects with confidence > {confidence*100}%.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEh7-cORUdol"
   },
   "source": [
    "# **Prediksi VS GT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1823,
     "status": "ok",
     "timestamp": 1751982896869,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "vTded3NOMr0x",
    "outputId": "17be2667-fbca-4591-bc37-4e6a48241ec9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from pycocotools.coco import COCO\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "# === Daftarkan Dataset COCO dengan metadata ===\n",
    "register_coco_instances(\n",
    "    \"roboflow_test\",\n",
    "    {\n",
    "        \"thing_classes\": [\"Cardiomegaly\", \"Nodule/Mass\", \"Pneumothorax\"]  # ganti sesuai kategori di COCO kamu\n",
    "    },\n",
    "    \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Dataset/dataset_new/test/_annotations.coco.json\",\n",
    "    \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Dataset/dataset_new/test\"\n",
    ")\n",
    "\n",
    "# === Load Konfigurasi Model Detectron2 ===\n",
    "# === Konfigurasi Model ===\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/epoch_50_1e-4_Adam/config.yaml\")\n",
    "cfg.MODEL.RETINANET.NUM_CLASSES = 3  # ganti sesuai jumlah kelas\n",
    "cfg.MODEL.SCORE_THRESH_TEST = 0.4\n",
    "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cfg.DATASETS.TEST = (\"roboflow_test\",)  # ganti sesuai nama dataset\n",
    "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/epoch_50_1e-4_Adam/best_model.pth\"\n",
    "predictor = DefaultPredictor(cfg)\n",
    "metadata = MetadataCatalog.get(\"roboflow_test\")  # ganti sesuai nama dataset kamu\n",
    "\n",
    "# === Load COCO Annotations ===\n",
    "annotation_path = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Dataset/dataset_new/test/_annotations.coco.json\"  # ganti path sesuai file .json kamu\n",
    "coco = COCO(annotation_path)\n",
    "\n",
    "# === Load 1 Gambar dan GT ===\n",
    "image_ids = coco.getImgIds()\n",
    "image_id = image_ids[5]  # pakai ID pertama yang tersedia\n",
    "image_info = coco.loadImgs(image_id)[0]\n",
    "image_path = os.path.join(\n",
    "    \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Dataset/dataset_new/test\",\n",
    "    image_info['file_name']\n",
    ")\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "image_rgb = image[..., ::-1]\n",
    "\n",
    "# Ground truth boxes & labels\n",
    "ann_ids = coco.getAnnIds(imgIds=image_id)\n",
    "annotations = coco.loadAnns(ann_ids)\n",
    "\n",
    "gt_boxes = []\n",
    "gt_labels = []\n",
    "for ann in annotations:\n",
    "    x, y, w, h = ann['bbox']\n",
    "    gt_boxes.append([x, y, x + w, y + h])\n",
    "    gt_labels.append(ann['category_id'] - 1)  # pastikan label index mulai dari 0\n",
    "\n",
    "# === Predict ===\n",
    "outputs = predictor(image)\n",
    "instances = outputs[\"instances\"]\n",
    "scores = instances.scores\n",
    "pred_boxes = instances.pred_boxes.tensor.cpu().numpy()\n",
    "pred_labels = instances.pred_classes.cpu().numpy()\n",
    "pred_scores = scores.cpu().numpy()\n",
    "\n",
    "# === Filter prediksi berdasarkan confidence threshold ===\n",
    "confidence = 0.4\n",
    "keep = pred_scores > confidence\n",
    "pred_boxes = pred_boxes[keep]\n",
    "pred_labels = pred_labels[keep]\n",
    "pred_scores = pred_scores[keep]\n",
    "\n",
    "# === Fungsi IoU ===\n",
    "def calculate_iou(box1, box2):\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "\n",
    "    inter = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    area1 = (box1[2]-box1[0]) * (box1[3]-box1[1])\n",
    "    area2 = (box2[2]-box2[0]) * (box2[3]-box2[1])\n",
    "    union = area1 + area2 - inter\n",
    "\n",
    "    return inter / union if union > 0 else 0\n",
    "\n",
    "# === Visualisasi ===\n",
    "fig, ax = plt.subplots(1, figsize=(12, 12))\n",
    "ax.imshow(image_rgb)\n",
    "\n",
    "# --- Gambar GT (hijau) ---\n",
    "for box, label in zip(gt_boxes, gt_labels):\n",
    "    xmin, ymin, xmax, ymax = box\n",
    "    rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                             linewidth=2, edgecolor='green', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(xmin, ymin - 5, f\"GT: {metadata.thing_classes[label]}\", color='green', fontsize=10)\n",
    "\n",
    "# --- Gambar Prediksi (merah) + IoU ---\n",
    "for box, score, label in zip(pred_boxes, pred_scores, pred_labels):\n",
    "    xmin, ymin, xmax, ymax = box\n",
    "    rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                             linewidth=2, edgecolor='red', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(xmin, ymax + 10, f\"Pred: {metadata.thing_classes[label]} ({score:.2f})\", color='red', fontsize=10)\n",
    "\n",
    "    # IoU dengan semua GT\n",
    "    for gt_box in gt_boxes:\n",
    "        iou = calculate_iou(box, gt_box)\n",
    "        if iou > 0.5:\n",
    "            ax.text(xmin, ymin - 20, f\"IoU: {iou:.2f}\", color='blue', fontsize=10)\n",
    "            break\n",
    "\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Detected {len(pred_boxes)} objects with confidence > {confidence*100:.0f}%.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1751981773250,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "3l8AlXhAQEm0",
    "outputId": "e98f802a-cfb8-4c91-d097-bc590eb1574c"
   },
   "outputs": [],
   "source": [
    "image_ids = coco.getImgIds()\n",
    "print(image_ids[:5])  # tampilkan 5 ID pertama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJrL2Y4NyW8_"
   },
   "source": [
    "# **Grafik Record Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 174,
     "status": "ok",
     "timestamp": 1749904446095,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "B-1Z2YZIQBxr",
    "outputId": "db80dbab-dd44-4085-9821-b2ee861502c7"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tentukan path ke file metrics.json\n",
    "metrics_file = '/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_Adam/metrics.json'  # Ganti dengan path file Anda\n",
    "\n",
    "# Menyaring data untuk total_loss\n",
    "iterations = []\n",
    "total_loss = []\n",
    "\n",
    "# Membaca file JSON baris per baris\n",
    "with open(metrics_file, 'r') as f:\n",
    "    for line in f:\n",
    "        # Memuat setiap baris JSON\n",
    "        entry = json.loads(line)\n",
    "\n",
    "        # Menyaring data untuk iteration dan total_loss\n",
    "        if 'iteration' in entry and 'total_loss' in entry:\n",
    "            iterations.append(entry['iteration'])\n",
    "            total_loss.append(entry['total_loss'])\n",
    "\n",
    "# Membuat grafik untuk total loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(iterations, total_loss, label=\"Total Loss\", color='tab:blue')\n",
    "\n",
    "# Menambahkan judul dan label sumbu\n",
    "plt.title('Total Loss over Iterations')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Total Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "# Menampilkan grafik\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1749904457099,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "HavZiOMcQNfm",
    "outputId": "c5d24e43-7044-48b2-c8db-596828ae2bb9"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tentukan path ke file metrics.json\n",
    "metrics_file = '/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_Adam/metrics.json'  # Ganti dengan path file Anda\n",
    "\n",
    "# Menyaring data untuk AP\n",
    "iterations = []\n",
    "bbox_ap = []\n",
    "bbox_ap50 = []\n",
    "bbox_ap75 = []\n",
    "bbox_ap_cardio = []\n",
    "bbox_ap_nodule = []\n",
    "bbox_ap_pneumo = []\n",
    "\n",
    "# Membaca file JSON baris per baris\n",
    "with open(metrics_file, 'r') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            entry = json.loads(line)\n",
    "\n",
    "            # Pastikan hanya memasukkan data yang mengandung metrik 'bbox/AP'\n",
    "            if 'bbox/AP' in entry:\n",
    "                iterations.append(entry['iteration'])\n",
    "                bbox_ap.append(entry['bbox/AP'])\n",
    "                bbox_ap50.append(entry.get('bbox/AP50', None))\n",
    "                bbox_ap75.append(entry.get('bbox/AP75', None))\n",
    "                bbox_ap_cardio.append(entry.get('bbox/AP-Cardiomegaly', None))\n",
    "                bbox_ap_nodule.append(entry.get('bbox/AP-Nodule-Mass', None))\n",
    "                bbox_ap_pneumo.append(entry.get('bbox/AP-Pneumothorax', None))\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing line: {e}\")\n",
    "            continue\n",
    "\n",
    "# Memastikan ada data untuk plotting\n",
    "print(f\"Total data points: {len(iterations)}\")\n",
    "\n",
    "# Jika ada data untuk plotting, buat grafik\n",
    "if iterations:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plotting berbagai metrik AP\n",
    "    plt.plot(iterations, bbox_ap, label=\"bbox/AP\", color='tab:blue')\n",
    "    plt.plot(iterations, bbox_ap50, label=\"bbox/AP50\", color='tab:orange')\n",
    "    plt.plot(iterations, bbox_ap75, label=\"bbox/AP75\", color='tab:green')\n",
    "    plt.plot(iterations, bbox_ap_cardio, label=\"bbox/AP-Cardiomegaly\", color='tab:red')\n",
    "    plt.plot(iterations, bbox_ap_nodule, label=\"bbox/AP-Nodule-Mass\", color='tab:purple')\n",
    "    plt.plot(iterations, bbox_ap_pneumo, label=\"bbox/AP-Pneumothorax\", color='tab:brown')\n",
    "\n",
    "    # Menambahkan judul dan label sumbu\n",
    "    plt.title('Average Precision (AP) over Iterations')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Average Precision (AP)')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Menampilkan legenda\n",
    "    plt.legend()\n",
    "\n",
    "    # Menampilkan grafik\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Tidak ada data untuk plot.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1749904470388,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "pBnNMS7DQXa3",
    "outputId": "3a7dad28-86a6-47e6-ce66-2be50e51ea87"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Menentukan path file metrics.json di Google Drive\n",
    "file_path = '/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_Adam/metrics.json'\n",
    "\n",
    "# Memuat file metrics.json\n",
    "with open(file_path, 'r') as file:\n",
    "    data = [json.loads(line) for line in file.readlines()]\n",
    "\n",
    "# Menyaring nilai AP per kelas dari data terakhir\n",
    "metrics = data[-1]  # Mengambil data terakhir yang berisi AP\n",
    "\n",
    "# Mengambil nilai AP per kelas\n",
    "ap_values = {\n",
    "    \"Cardiomegaly\": metrics.get('bbox/AP-Cardiomegaly', 0),\n",
    "    \"Nodule-Mass\": metrics.get('bbox/AP-Nodule-Mass', 0),\n",
    "    \"Pneumothorax\": metrics.get('bbox/AP-Pneumothorax', 0),\n",
    "}\n",
    "\n",
    "# Menghitung mAP (mean Average Precision)\n",
    "ap_values_list = list(ap_values.values())\n",
    "map_score = sum(ap_values_list) / len(ap_values_list)\n",
    "\n",
    "# Menampilkan hasil\n",
    "print(\"AP per kelas:\")\n",
    "for class_name, ap in ap_values.items():\n",
    "    print(f\"{class_name}: {ap:.4f}\")\n",
    "\n",
    "print(f\"\\nmAP: {map_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 185,
     "status": "ok",
     "timestamp": 1749904481189,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "cgcjrbBcQf7H",
    "outputId": "7bbc3592-1e37-44aa-f6fa-392c52101f94"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Menentukan path file metrics.json (update dengan path yang sesuai)\n",
    "file_path = '/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_Adam/metrics.json'\n",
    "\n",
    "# Memuat file metrics.json\n",
    "with open(file_path, 'r') as file:\n",
    "    data = [json.loads(line) for line in file.readlines()]\n",
    "\n",
    "# Menyaring nilai AP per kelas dari data terakhir\n",
    "ap_per_iteration = []\n",
    "map_per_iteration = []\n",
    "\n",
    "# Menyaring nilai AP per kelas dan mAP dari setiap iterasi\n",
    "for metrics in data:\n",
    "    # Mengecek apakah nilai AP ada dalam data\n",
    "    if 'bbox/AP-Cardiomegaly' in metrics and 'bbox/AP-Nodule-Mass' in metrics and 'bbox/AP-Pneumothorax' in metrics:\n",
    "        ap_values = {\n",
    "            \"Cardiomegaly\": metrics.get('bbox/AP-Cardiomegaly', 0),\n",
    "            \"Nodule-Mass\": metrics.get('bbox/AP-Nodule-Mass', 0),\n",
    "            \"Pneumothorax\": metrics.get('bbox/AP-Pneumothorax', 0),\n",
    "        }\n",
    "\n",
    "        # Menghitung mAP (mean Average Precision)\n",
    "        ap_values_list = list(ap_values.values())\n",
    "        map_score = sum(ap_values_list) / len(ap_values_list)\n",
    "\n",
    "        ap_per_iteration.append(ap_values)\n",
    "        map_per_iteration.append(map_score)\n",
    "\n",
    "# Menyiapkan data untuk grafik\n",
    "iterations = range(1, len(map_per_iteration) + 1)\n",
    "\n",
    "# Plotting mAP per iterasi\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(iterations, map_per_iteration, label='mAP (mean Average Precision)', color='blue', linewidth=2)\n",
    "\n",
    "# Menambahkan grafik untuk setiap kelas\n",
    "for class_name in ap_per_iteration[0].keys():\n",
    "    class_ap_values = [ap[class_name] for ap in ap_per_iteration]\n",
    "    plt.plot(iterations, class_ap_values, label=f'AP-{class_name}', linestyle='--')\n",
    "\n",
    "# Menambahkan label dan judul\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Average Precision')\n",
    "plt.title('mAP and AP per Class over Iterations')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Menampilkan grafik\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 137,
     "status": "ok",
     "timestamp": 1749904487926,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "WM8_47H0Qs0h",
    "outputId": "ed9c72aa-ee28-4726-9c1f-714d1f0d310a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Path file di Google Drive (sesuaikan dengan path file Anda)\n",
    "file_path = '/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_Adam/metrics.json'\n",
    "\n",
    "# Memuat data dari file metrics.json\n",
    "with open(file_path, 'r') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# Menyiapkan data untuk plot\n",
    "iterations = []\n",
    "loss_cls_values = []\n",
    "loss_box_reg_values = []\n",
    "\n",
    "# Looping untuk mengekstrak data\n",
    "for metrics in data:\n",
    "    # Pastikan ada key yang dibutuhkan\n",
    "    if 'iteration' in metrics:\n",
    "        iterations.append(metrics['iteration'])\n",
    "    if 'loss_cls' in metrics:\n",
    "        loss_cls_values.append(metrics['loss_cls'])\n",
    "    if 'loss_box_reg' in metrics:\n",
    "        loss_box_reg_values.append(metrics['loss_box_reg'])\n",
    "\n",
    "# Pastikan panjang data sama, dan jika tidak, sesuaikan panjangnya\n",
    "min_len = min(len(iterations), len(loss_cls_values), len(loss_box_reg_values))\n",
    "\n",
    "# Potong data agar memiliki panjang yang sama\n",
    "iterations = iterations[:min_len]\n",
    "loss_cls_values = loss_cls_values[:min_len]\n",
    "loss_box_reg_values = loss_box_reg_values[:min_len]\n",
    "\n",
    "# Membuat plot jika data ada\n",
    "if iterations and loss_cls_values and loss_box_reg_values:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot Loss Klasifikasi\n",
    "    plt.plot(iterations, loss_cls_values, label='Loss Klasifikasi', color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "    # Plot Loss Regresi Batas\n",
    "    plt.plot(iterations, loss_box_reg_values, label='Loss Regresi Batas', color='green', linestyle='-', linewidth=2)\n",
    "\n",
    "    # Menambahkan label dan judul\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Klasifikasi dan Loss Regresi Batas selama Iterasi')\n",
    "\n",
    "    # Menambahkan legend\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    # Menampilkan grid\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Menampilkan grafik\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Data tidak lengkap, pastikan key 'loss_cls' dan 'loss_box_reg' ada dalam setiap entri.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YeAEYr2ydqu"
   },
   "source": [
    "# **Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y9iTukTWQ5gv"
   },
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    box: [xmin, ymin, xmax, ymax]\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x1g, y1g, x2g, y2g = box2\n",
    "\n",
    "    xi1 = max(x1, x1g)\n",
    "    yi1 = max(y1, y1g)\n",
    "    xi2 = min(x2, x2g)\n",
    "    yi2 = min(y2, y2g)\n",
    "    inter_area = max(xi2 - xi1, 0) * max(yi2 - yi1, 0)\n",
    "\n",
    "    box1_area = (x2 - x1) * (y2 - y1)\n",
    "    box2_area = (x2g - x1g) * (y2g - y1g)\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "    if union_area == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return inter_area / union_area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "executionInfo": {
     "elapsed": 14830,
     "status": "ok",
     "timestamp": 1749904528830,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "pDWZUa9FQ8dM",
    "outputId": "e1c1eb15-160f-430c-9688-eb0da7ecbbf6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# ðŸ§  Load model\n",
    "# cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"best_model.pth\")\n",
    "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_Adam/best_model.pth\"\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# ðŸ“š Prepare dataset paths\n",
    "test_image_dir = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Dataset/dataset_new/test\"\n",
    "coco_annotation_path = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Dataset/dataset_new/test/_annotations.coco.json\"\n",
    "\n",
    "# Load COCO ground truth\n",
    "with open(coco_annotation_path) as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# Build image_id to filename mapping\n",
    "id_to_filename = {img['id']: img['file_name'] for img in coco_data['images']}\n",
    "\n",
    "# Build annotations mapping\n",
    "annotations = coco_data['annotations']\n",
    "gt_dict = {}  # {filename: (boxes, labels)}\n",
    "\n",
    "for ann in annotations:\n",
    "    image_id = ann['image_id']\n",
    "    filename = id_to_filename[image_id]\n",
    "    bbox = ann['bbox']  # [x, y, width, height]\n",
    "    category_id = ann['category_id']\n",
    "\n",
    "    if filename not in gt_dict:\n",
    "        gt_dict[filename] = {'boxes': [], 'labels': []}\n",
    "\n",
    "    # Convert bbox format to [xmin, ymin, xmax, ymax]\n",
    "    xmin, ymin, w, h = bbox\n",
    "    xmax = xmin + w\n",
    "    ymax = ymin + h\n",
    "\n",
    "    gt_dict[filename]['boxes'].append([xmin, ymin, xmax, ymax])\n",
    "    gt_dict[filename]['labels'].append(category_id)\n",
    "\n",
    "# Build category_id to class_name mapping\n",
    "category_id_to_name = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
    "class_names = [category_id_to_name[i] for i in sorted(category_id_to_name.keys())]\n",
    "\n",
    "# ðŸ”¥ Start evaluating\n",
    "y_true = []\n",
    "y_pred = []\n",
    "iou_threshold = 0.5\n",
    "confidence_threshold = 0.5\n",
    "\n",
    "test_images = sorted(os.listdir(test_image_dir))\n",
    "test_images = [img for img in test_images if img.endswith('.jpg') or img.endswith('.png')]\n",
    "\n",
    "for img_file in tqdm(test_images, desc=\"Processing Test Images\"):\n",
    "    # Read image\n",
    "    img_path = os.path.join(test_image_dir, img_file)\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    if img_file not in gt_dict:\n",
    "        continue  # skip images without ground truth\n",
    "\n",
    "    gt_boxes = np.array(gt_dict[img_file]['boxes'])\n",
    "    gt_classes = np.array(gt_dict[img_file]['labels'])\n",
    "\n",
    "    # Predict\n",
    "    outputs = predictor(img)\n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "\n",
    "    pred_boxes = instances.pred_boxes.tensor.numpy()\n",
    "    pred_classes = instances.pred_classes.numpy()\n",
    "    pred_scores = instances.scores.numpy()\n",
    "\n",
    "    # Filter predictions by confidence\n",
    "    keep = pred_scores > confidence_threshold\n",
    "    pred_boxes = pred_boxes[keep]\n",
    "    pred_classes = pred_classes[keep]\n",
    "\n",
    "    matched_gt = set()\n",
    "\n",
    "    # Matching predicted boxes to ground truth boxes\n",
    "    for pred_box, pred_class in zip(pred_boxes, pred_classes):\n",
    "        best_iou = 0\n",
    "        best_idx = -1\n",
    "        for idx, gt_box in enumerate(gt_boxes):\n",
    "            iou = calculate_iou(pred_box, gt_box)\n",
    "            if iou > best_iou and idx not in matched_gt:\n",
    "                best_iou = iou\n",
    "                best_idx = idx\n",
    "        if best_iou >= iou_threshold and best_idx != -1:\n",
    "            y_true.append(gt_classes[best_idx])\n",
    "            y_pred.append(pred_class)\n",
    "            matched_gt.add(best_idx)\n",
    "        else:\n",
    "            # False positive\n",
    "            y_true.append(-1)  # background\n",
    "            y_pred.append(pred_class)\n",
    "\n",
    "    # False negatives\n",
    "    for idx, gt_class in enumerate(gt_classes):\n",
    "        if idx not in matched_gt:\n",
    "            y_true.append(gt_class)\n",
    "            y_pred.append(-1)\n",
    "\n",
    "# ðŸ”¥ Build Confusion Matrix\n",
    "all_labels = sorted(list(set([lab for lab in y_true if lab != -1] + [lab for lab in y_pred if lab != -1])))\n",
    "cm = confusion_matrix(y_true, y_pred, labels=all_labels)\n",
    "\n",
    "class_labels = [category_id_to_name[i] for i in all_labels]\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix - RetinaNet Detectron2 (COCO Format)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikCeW_Fr_LS2"
   },
   "source": [
    "# Prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4T6siLd4_OJQ"
   },
   "outputs": [],
   "source": [
    "# ðŸ“¦ Install dependencies\n",
    "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
    "# !pip install -q pycocotools\n",
    "\n",
    "# import torch\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "from detectron2.engine import DefaultPredictor\n",
    "# from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.checkpoint import DetectionCheckpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 741
    },
    "executionInfo": {
     "elapsed": 1183,
     "status": "ok",
     "timestamp": 1747917583656,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "q0NcvO9I_VZL",
    "outputId": "a1f82adc-20ca-4331-cde4-bbfd4238cf7d"
   },
   "outputs": [],
   "source": [
    "# ðŸ’¡ Load the config file (you still need this to define model structure)\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/epoch_50_1e-4_Adam/config.yaml\")\n",
    "#cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Set score threshold\n",
    "\n",
    "# ðŸ” Set path to best model\n",
    "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/epoch_50_1e-4_Adam/best_model.pth\"\n",
    "\n",
    "# ðŸ”§ Build model manually (optional alternative to DefaultPredictor if you want more control)\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# ðŸ–¼ï¸ Load and run inference on an image\n",
    "image_path = '/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Dataset/test/9ed1f91369552618456da255b02820b3_jpg.rf.17cd671024249e0b1f3a9e36be41a928.jpg'\n",
    "im = cv2.imread(image_path)\n",
    "\n",
    "outputs = predictor(im)\n",
    "\n",
    "# Filter instances with confidence\n",
    "confidence = 0.5\n",
    "instances = outputs[\"instances\"]\n",
    "scores = instances.scores\n",
    "filtered_instances = instances[scores > confidence]\n",
    "print(filtered_instances)\n",
    "\n",
    "\n",
    "# ðŸŽ¨ Visualize\n",
    "MetadataCatalog.get(\"roboflow_train\").thing_classes = [\"objects\", \"Cardiomegaly\", \"Nodule-Mass\", \"Pneumothorax\"]\n",
    "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(\"roboflow_train\"), scale=1)\n",
    "v = v.draw_instance_predictions(filtered_instances.to(\"cpu\"))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(v.get_image())\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Detected {len(filtered_instances)} objects with confidence > {confidence*100}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jcNhEh7YJbB"
   },
   "source": [
    "# **Evaluasi Data Train, Validation, dan Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1458208,
     "status": "ok",
     "timestamp": 1749906029085,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "aLiD9rlpYMfb",
    "outputId": "1dc5dc0a-5abd-44c6-fe8e-008ec7a69a07"
   },
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.modeling import build_model\n",
    "\n",
    "# Load config dan model\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_Adam/config.yaml\")\n",
    "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_Adam/best_model.pth\"\n",
    "cfg.MODEL.DEVICE = 'cpu'  # atau 'cpu'\n",
    "cfg.DATASETS.TEST = (\"roboflow_train\",)\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.5\n",
    "\n",
    "evaluator = COCOEvaluator(\"roboflow_train\", cfg, False, output_dir=\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_Adam/eval_train\")\n",
    "val_loader = build_detection_test_loader(cfg, \"roboflow_train\")\n",
    "\n",
    "model = build_model(cfg)\n",
    "DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)\n",
    "\n",
    "results = inference_on_dataset(model, val_loader, evaluator)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 172513,
     "status": "ok",
     "timestamp": 1749907524683,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "PYhbwqaecwxz",
    "outputId": "46bcca6f-c545-4342-c914-d9ffa506cf00"
   },
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.modeling import build_model\n",
    "\n",
    "# Load config dan model\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_Adam/config.yaml\")\n",
    "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_Adam/best_model.pth\"\n",
    "cfg.MODEL.DEVICE = 'cpu'  # atau 'cpu'\n",
    "cfg.DATASETS.TEST = (\"roboflow_val\",)\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.5\n",
    "\n",
    "evaluator = COCOEvaluator(\"roboflow_val\", cfg, False, output_dir=\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_Adam/eval_valid\")\n",
    "val_loader = build_detection_test_loader(cfg, \"roboflow_val\")\n",
    "\n",
    "model = build_model(cfg)\n",
    "DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)\n",
    "\n",
    "results = inference_on_dataset(model, val_loader, evaluator)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 177658,
     "status": "ok",
     "timestamp": 1749907326395,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "Fa6FP2Nfdx3u",
    "outputId": "7b7c7517-5660-46bb-e4a5-3f80f0f7e8d3"
   },
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.modeling import build_model\n",
    "\n",
    "# Load config dan model\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_Adam/config.yaml\")\n",
    "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_Adam/best_model.pth\"\n",
    "cfg.MODEL.DEVICE = 'cpu'  # atau 'cpu'\n",
    "cfg.DATASETS.TEST = (\"roboflow_test_1\",)\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.5\n",
    "\n",
    "evaluator = COCOEvaluator(\"roboflow_test_1\", cfg, False, output_dir=\"/content/drive/MyDrive/210411100014_Taufiqu Reza Yoga Pratama/Model/new/epoch_50_1e-4_Adam/eval_test\")\n",
    "val_loader = build_detection_test_loader(cfg, \"roboflow_test_1\")\n",
    "\n",
    "model = build_model(cfg)\n",
    "DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)\n",
    "\n",
    "results = inference_on_dataset(model, val_loader, evaluator)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cqv0ySxdjy7B"
   },
   "outputs": [],
   "source": [
    "from detectron2.evaluation.evaluator import DatasetEvaluator\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class PRF1Evaluator(DatasetEvaluator):\n",
    "    def __init__(self, dataset_name, metadata, class_names=None):\n",
    "        from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "        self.metadata = MetadataCatalog.get(dataset_name)\n",
    "        self.dataset_dicts = DatasetCatalog.get(dataset_name)\n",
    "        self.class_names = class_names if class_names else self.metadata.thing_classes\n",
    "        self.gts = []\n",
    "        self.preds = []\n",
    "\n",
    "        # Buat mapping image_id ke daftar ground truth class ID\n",
    "        self.imgid_to_gt = {}\n",
    "        for data in self.dataset_dicts:\n",
    "            gt_classes = [ann[\"category_id\"] for ann in data[\"annotations\"]]\n",
    "            self.imgid_to_gt[data[\"image_id\"]] = gt_classes\n",
    "\n",
    "    def reset(self):\n",
    "        self.gts = []\n",
    "        self.preds = []\n",
    "\n",
    "    def process(self, inputs, outputs):\n",
    "        for input, output in zip(inputs, outputs):\n",
    "            img_id = input[\"image_id\"]\n",
    "            gt_classes = self.imgid_to_gt.get(img_id, [])\n",
    "            pred_classes = output[\"instances\"].pred_classes.cpu().numpy() if len(output[\"instances\"]) > 0 else []\n",
    "\n",
    "            # Samakan panjang prediksi dan ground truth\n",
    "            if len(pred_classes) < len(gt_classes):\n",
    "                pred_classes = list(pred_classes) + [-1] * (len(gt_classes) - len(pred_classes))\n",
    "            elif len(pred_classes) > len(gt_classes):\n",
    "                pred_classes = pred_classes[:len(gt_classes)]\n",
    "\n",
    "            self.gts.extend(gt_classes)\n",
    "            self.preds.extend(pred_classes)\n",
    "\n",
    "    def evaluate(self):\n",
    "        print(\"\\n==== Precision, Recall, and F1-Score per Class ====\\n\")\n",
    "\n",
    "        # Ambil hasil sebagai dictionary\n",
    "        report_dict = classification_report(\n",
    "            self.gts,\n",
    "            self.preds,\n",
    "            target_names=self.class_names,\n",
    "            output_dict=True,\n",
    "            digits=3,\n",
    "            zero_division=0\n",
    "        )\n",
    "\n",
    "        # Konversi ke DataFrame\n",
    "        df = pd.DataFrame(report_dict).transpose()\n",
    "        df.index.name = 'Class'\n",
    "\n",
    "        # Ambil dan simpan nilai akurasi, hapus dari tabel supaya tampil rapi\n",
    "        accuracy = report_dict.get(\"accuracy\", None)\n",
    "        if \"accuracy\" in df.index:\n",
    "            df.drop(\"accuracy\", inplace=True)\n",
    "\n",
    "        # Ubah support menjadi integer\n",
    "        if 'support' in df.columns:\n",
    "            df['support'] = df['support'].astype(int)\n",
    "\n",
    "        # Urutkan kolom\n",
    "        df = df[['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "        # Cetak tabel\n",
    "        print(df.to_string(float_format=\"%.3f\"))\n",
    "\n",
    "        # Cetak akurasi secara terpisah\n",
    "        if accuracy is not None:\n",
    "            print(f\"\\nOverall Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "        # Return hanya data, tanpa tampilkan dict sebagai output Python\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67895,
     "status": "ok",
     "timestamp": 1749908700564,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "O8j9HYfRj3v0",
    "outputId": "1fd8b17e-d30a-4961-c952-642f69509a18"
   },
   "outputs": [],
   "source": [
    "class_names = [\"Cardiomegaly\", \"Nodule/Mass\", \"Pneumothorax\"]\n",
    "\n",
    "evaluator_test = PRF1Evaluator(\"roboflow_train\", cfg, class_names=class_names)\n",
    "test_loader = build_detection_test_loader(cfg, \"roboflow_train\")\n",
    "inference_on_dataset(trainer.model, test_loader, evaluator_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8612,
     "status": "ok",
     "timestamp": 1749908721087,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "pKS0gynkpfII",
    "outputId": "0a57cbad-4784-439f-90ca-a04be2a70804"
   },
   "outputs": [],
   "source": [
    "class_names = [\"Cardiomegaly\", \"Nodule/Mass\", \"Pneumothorax\"]\n",
    "\n",
    "evaluator_test = PRF1Evaluator(\"roboflow_val\", cfg, class_names=class_names)\n",
    "test_loader = build_detection_test_loader(cfg, \"roboflow_val\")\n",
    "inference_on_dataset(trainer.model, test_loader, evaluator_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8694,
     "status": "ok",
     "timestamp": 1749908748173,
     "user": {
      "displayName": "Al Qunnah",
      "userId": "06050257527007666949"
     },
     "user_tz": -420
    },
    "id": "su7GgBgBpiu9",
    "outputId": "d9e8a8d2-4cd1-4a44-9d4d-90262fc0d237"
   },
   "outputs": [],
   "source": [
    "class_names = [\"Cardiomegaly\", \"Nodule/Mass\", \"Pneumothorax\"]\n",
    "\n",
    "evaluator_test = PRF1Evaluator(\"roboflow_test_1\", cfg, class_names=class_names)\n",
    "test_loader = build_detection_test_loader(cfg, \"roboflow_test_1\")\n",
    "inference_on_dataset(trainer.model, test_loader, evaluator_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMcXT52Y899yCAFzLcEGcVl",
   "gpuType": "T4",
   "machine_shape": "hm",
   "mount_file_id": "1hSUgyn8nPtBpsOTqtHh-UbimX3yPiCEr",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
